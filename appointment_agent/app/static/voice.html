<!--<!DOCTYPE html>-->
<!--<html lang="en">-->
<!--<head>-->
<!--    <meta charset="UTF-8">-->
<!--    <meta name="viewport" content="width=device-width, initial-scale=1.0">-->
<!--    <title>Voice Medical Appointment Assistant</title>-->
<!--    <style>-->
<!--        * {-->
<!--            margin: 0;-->
<!--            padding: 0;-->
<!--            box-sizing: border-box;-->
<!--        }-->

<!--        body {-->
<!--            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            height: 100vh;-->
<!--            display: flex;-->
<!--            justify-content: center;-->
<!--            align-items: center;-->
<!--            padding: 20px;-->
<!--        }-->

<!--        .voice-container {-->
<!--            width: 100%;-->
<!--            max-width: 800px;-->
<!--            background: white;-->
<!--            border-radius: 20px;-->
<!--            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);-->
<!--            padding: 40px;-->
<!--            text-align: center;-->
<!--        }-->

<!--        .header {-->
<!--            margin-bottom: 30px;-->
<!--        }-->

<!--        .header h1 {-->
<!--            font-size: 32px;-->
<!--            color: #667eea;-->
<!--            margin-bottom: 10px;-->
<!--        }-->

<!--        .header p {-->
<!--            color: #666;-->
<!--            font-size: 16px;-->
<!--        }-->

<!--        .mode-toggle {-->
<!--            display: flex;-->
<!--            justify-content: center;-->
<!--            gap: 10px;-->
<!--            margin-bottom: 30px;-->
<!--        }-->

<!--        .mode-btn {-->
<!--            padding: 10px 20px;-->
<!--            border: 2px solid #667eea;-->
<!--            background: white;-->
<!--            color: #667eea;-->
<!--            border-radius: 25px;-->
<!--            cursor: pointer;-->
<!--            font-size: 14px;-->
<!--            font-weight: 600;-->
<!--            transition: all 0.3s;-->
<!--        }-->

<!--        .mode-btn.active {-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            color: white;-->
<!--        }-->

<!--        .mode-btn:hover {-->
<!--            transform: translateY(-2px);-->
<!--            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);-->
<!--        }-->

<!--        .microphone-wrapper {-->
<!--            margin: 40px 0;-->
<!--        }-->

<!--        .microphone-button {-->
<!--            width: 120px;-->
<!--            height: 120px;-->
<!--            border-radius: 50%;-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            border: none;-->
<!--            cursor: pointer;-->
<!--            display: inline-flex;-->
<!--            align-items: center;-->
<!--            justify-content: center;-->
<!--            transition: all 0.3s;-->
<!--            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);-->
<!--        }-->

<!--        .microphone-button:hover {-->
<!--            transform: scale(1.1);-->
<!--            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.6);-->
<!--        }-->

<!--        .microphone-button.listening {-->
<!--            animation: pulse 1.5s infinite;-->
<!--            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);-->
<!--        }-->

<!--        .microphone-button.processing {-->
<!--            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);-->
<!--        }-->

<!--        @keyframes pulse {-->
<!--            0%, 100% {-->
<!--                transform: scale(1);-->
<!--                box-shadow: 0 10px 30px rgba(240, 147, 251, 0.4);-->
<!--            }-->
<!--            50% {-->
<!--                transform: scale(1.1);-->
<!--                box-shadow: 0 15px 40px rgba(240, 147, 251, 0.6);-->
<!--            }-->
<!--        }-->

<!--        .microphone-icon {-->
<!--            font-size: 48px;-->
<!--            color: white;-->
<!--        }-->

<!--        .status {-->
<!--            font-size: 18px;-->
<!--            color: #667eea;-->
<!--            margin: 20px 0;-->
<!--            min-height: 30px;-->
<!--            font-weight: 600;-->
<!--        }-->

<!--        .transcript-section {-->
<!--            margin: 30px 0;-->
<!--            text-align: left;-->
<!--        }-->

<!--        .transcript-box {-->
<!--            background: #f7f7f7;-->
<!--            border-radius: 15px;-->
<!--            padding: 20px;-->
<!--            min-height: 150px;-->
<!--            max-height: 300px;-->
<!--            overflow-y: auto;-->
<!--        }-->

<!--        .transcript-label {-->
<!--            font-weight: 600;-->
<!--            color: #667eea;-->
<!--            margin-bottom: 10px;-->
<!--            display: block;-->
<!--        }-->

<!--        .transcript-text {-->
<!--            color: #333;-->
<!--            line-height: 1.6;-->
<!--            margin-bottom: 15px;-->
<!--        }-->

<!--        .transcript-text.user {-->
<!--            color: #764ba2;-->
<!--            font-weight: 500;-->
<!--        }-->

<!--        .transcript-text.assistant {-->
<!--            color: #667eea;-->
<!--        }-->

<!--        .controls {-->
<!--            display: flex;-->
<!--            justify-content: center;-->
<!--            gap: 15px;-->
<!--            margin-top: 30px;-->
<!--        }-->

<!--        .control-btn {-->
<!--            padding: 12px 24px;-->
<!--            border: none;-->
<!--            border-radius: 25px;-->
<!--            cursor: pointer;-->
<!--            font-size: 14px;-->
<!--            font-weight: 600;-->
<!--            transition: all 0.3s;-->
<!--        }-->

<!--        .control-btn.primary {-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            color: white;-->
<!--        }-->

<!--        .control-btn.secondary {-->
<!--            background: #f44336;-->
<!--            color: white;-->
<!--        }-->

<!--        .control-btn:hover {-->
<!--            transform: translateY(-2px);-->
<!--            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);-->
<!--        }-->

<!--        .control-btn:disabled {-->
<!--            opacity: 0.5;-->
<!--            cursor: not-allowed;-->
<!--            transform: none;-->
<!--        }-->

<!--        .error-message {-->
<!--            background: #ffebee;-->
<!--            color: #c62828;-->
<!--            padding: 15px;-->
<!--            border-radius: 10px;-->
<!--            margin-top: 20px;-->
<!--            display: none;-->
<!--        }-->

<!--        .error-message.show {-->
<!--            display: block;-->
<!--        }-->

<!--        .back-link {-->
<!--            margin-top: 20px;-->
<!--        }-->

<!--        .back-link a {-->
<!--            color: #667eea;-->
<!--            text-decoration: none;-->
<!--            font-weight: 600;-->
<!--        }-->

<!--        .back-link a:hover {-->
<!--            text-decoration: underline;-->
<!--        }-->
<!--    </style>-->
<!--</head>-->
<!--<body>-->
<!--    <div class="voice-container">-->
<!--        <div class="header">-->
<!--            <h1>üé§ Voice Medical Assistant</h1>-->
<!--            <p>Talk to book, cancel, or manage your appointments</p>-->
<!--        </div>-->

<!--        <div class="mode-toggle">-->
<!--            <a href="/" style="text-decoration: none;">-->
<!--                <button class="mode-btn">üí¨ Text Chat</button>-->
<!--            </a>-->
<!--            <button class="mode-btn active">üé§ Voice Chat</button>-->
<!--        </div>-->

<!--        <div class="microphone-wrapper">-->
<!--            <button class="microphone-button" id="micButton">-->
<!--                <span class="microphone-icon">üé§</span>-->
<!--            </button>-->
<!--        </div>-->

<!--        <div class="status" id="status">Click microphone to start</div>-->

<!--        <div class="transcript-section">-->
<!--            <div class="transcript-box" id="transcriptBox">-->
<!--                <span class="transcript-label">Conversation:</span>-->
<!--                <div id="conversation"></div>-->
<!--            </div>-->
<!--        </div>-->

<!--        <div class="controls">-->
<!--            <button class="control-btn secondary" id="clearBtn">Clear Conversation</button>-->
<!--        </div>-->

<!--        <div class="error-message" id="errorMessage"></div>-->

<!--        <div class="back-link">-->
<!--            <a href="/">‚Üê Switch to Text Chat</a>-->
<!--        </div>-->
<!--    </div>-->

<!--    <script>-->
<!--        let websocket = null;-->
<!--        let mediaRecorder = null;-->
<!--        let audioContext = null;-->
<!--        let isListening = false;-->
<!--        let audioQueue = [];-->
<!--        let isPlayingAudio = false;-->

<!--        const micButton = document.getElementById('micButton');-->
<!--        const status = document.getElementById('status');-->
<!--        const conversation = document.getElementById('conversation');-->
<!--        const errorMessage = document.getElementById('errorMessage');-->
<!--        const clearBtn = document.getElementById('clearBtn');-->

<!--        function showError(message) {-->
<!--            errorMessage.textContent = message;-->
<!--            errorMessage.classList.add('show');-->
<!--            setTimeout(() => {-->
<!--                errorMessage.classList.remove('show');-->
<!--            }, 5000);-->
<!--        }-->

<!--        function updateStatus(message, className = '') {-->
<!--            status.textContent = message;-->
<!--            micButton.className = 'microphone-button ' + className;-->
<!--        }-->

<!--        function addToConversation(text, isUser) {-->
<!--            const div = document.createElement('div');-->
<!--            div.className = `transcript-text ${isUser ? 'user' : 'assistant'}`;-->
<!--            div.textContent = `${isUser ? 'You' : 'Assistant'}: ${text}`;-->
<!--            conversation.appendChild(div);-->
<!--            document.getElementById('transcriptBox').scrollTop = document.getElementById('transcriptBox').scrollHeight;-->
<!--        }-->

<!--        async function playAudio(audioData) {-->
<!--            return new Promise((resolve) => {-->
<!--                const audioBlob = new Blob([audioData], { type: 'audio/mpeg' });-->
<!--                const audioUrl = URL.createObjectURL(audioBlob);-->
<!--                const audio = new Audio(audioUrl);-->

<!--                audio.onended = () => {-->
<!--                    URL.revokeObjectURL(audioUrl);-->
<!--                    resolve();-->
<!--                };-->

<!--                audio.onerror = (error) => {-->
<!--                    console.error('Audio playback error:', error);-->
<!--                    resolve();-->
<!--                };-->

<!--                audio.play().catch(error => {-->
<!--                    console.error('Play error:', error);-->
<!--                    resolve();-->
<!--                });-->
<!--            });-->
<!--        }-->

<!--        async function processAudioQueue() {-->
<!--            if (isPlayingAudio || audioQueue.length === 0) return;-->

<!--            isPlayingAudio = true;-->
<!--            const audioData = audioQueue.shift();-->
<!--            await playAudio(audioData);-->
<!--            isPlayingAudio = false;-->

<!--            if (audioQueue.length > 0) {-->
<!--                processAudioQueue();-->
<!--            }-->
<!--        }-->

<!--        async function connectWebSocket() {-->
<!--            return new Promise((resolve, reject) => {-->
<!--                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';-->
<!--&lt;!&ndash;                const wsUrl = `${protocol}//${window.location.host}/api/voice/ws`;&ndash;&gt;-->
<!--                const pathParts = location.pathname.split('/').filter(p => p);-->
<!--                const basePath = pathParts.length > 0 ? `/${pathParts[0]}` : '';-->

<!--                websocket = new WebSocket(`${protocol}//${location.host}${basePath}/api/voice/ws`);-->

<!--                console.log('Connecting to:', wsUrl);-->
<!--                websocket = new WebSocket(wsUrl);-->

<!--                websocket.onopen = () => {-->
<!--                    console.log('WebSocket connected');-->
<!--                    updateStatus('Connected - Ready to listen', '');-->
<!--                    resolve();-->
<!--                };-->

<!--                websocket.onmessage = async (event) => {-->
<!--                    if (event.data instanceof Blob) {-->
<!--                        // Audio data received-->
<!--                        console.log('Received audio blob:', event.data.size, 'bytes');-->
<!--                        const arrayBuffer = await event.data.arrayBuffer();-->
<!--                        audioQueue.push(arrayBuffer);-->
<!--                        processAudioQueue();-->
<!--                    } else {-->
<!--                        // JSON message-->
<!--                        const data = JSON.parse(event.data);-->
<!--                        console.log('Received:', data);-->

<!--                        if (data.type === 'status') {-->
<!--                            updateStatus(data.message, data.message.includes('Speaking') ? 'processing' : 'listening');-->
<!--                        } else if (data.type === 'transcript') {-->
<!--                            addToConversation(data.text, true);-->
<!--                        } else if (data.type === 'response') {-->
<!--                            addToConversation(data.text, false);-->
<!--                        } else if (data.type === 'interim_transcript') {-->
<!--                            updateStatus(`Hearing: "${data.text}"`, 'listening');-->
<!--                        } else if (data.type === 'audio_complete') {-->
<!--                            console.log('Audio playback complete');-->
<!--                        } else if (data.type === 'error') {-->
<!--                            showError(data.message);-->
<!--                        }-->
<!--                    }-->
<!--                };-->

<!--                websocket.onerror = (error) => {-->
<!--                    console.error('WebSocket error:', error);-->
<!--                    showError('Connection error occurred');-->
<!--                    reject(error);-->
<!--                };-->

<!--                websocket.onclose = () => {-->
<!--                    console.log('WebSocket closed');-->
<!--                    updateStatus('Disconnected - Click mic to reconnect', '');-->
<!--                    isListening = false;-->
<!--                    websocket = null;-->
<!--                };-->

<!--                // Timeout after 5 seconds-->
<!--                setTimeout(() => {-->
<!--                    if (websocket && websocket.readyState !== WebSocket.OPEN) {-->
<!--                        reject(new Error('Connection timeout'));-->
<!--                    }-->
<!--                }, 5000);-->
<!--            });-->
<!--        }-->

<!--        async function startListening() {-->
<!--            try {-->
<!--                const stream = await navigator.mediaDevices.getUserMedia({-->
<!--                    audio: {-->
<!--                        channelCount: 1,-->
<!--                        sampleRate: 16000,-->
<!--                        echoCancellation: true,-->
<!--                        noiseSuppression: true,-->
<!--                        autoGainControl: true-->
<!--                    }-->
<!--                });-->

<!--                console.log('Microphone access granted');-->

<!--                audioContext = new (window.AudioContext || window.webkitAudioContext)({-->
<!--                    sampleRate: 16000-->
<!--                });-->

<!--                await audioContext.resume();-->

<!--                const source = audioContext.createMediaStreamSource(stream);-->
<!--                const processor = audioContext.createScriptProcessor(4096, 1, 1);-->

<!--                source.connect(processor);-->
<!--                processor.connect(audioContext.destination);-->

<!--                processor.onaudioprocess = (e) => {-->
<!--                    if (websocket && websocket.readyState === WebSocket.OPEN && isListening) {-->
<!--                        const inputData = e.inputBuffer.getChannelData(0);-->

<!--                        // Convert to 16-bit PCM-->
<!--                        const pcm16 = new Int16Array(inputData.length);-->
<!--                        for (let i = 0; i < inputData.length; i++) {-->
<!--                            const s = Math.max(-1, Math.min(1, inputData[i]));-->
<!--                            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;-->
<!--                        }-->

<!--                        // Send as bytes-->
<!--                        websocket.send(pcm16.buffer);-->
<!--                    }-->
<!--                };-->

<!--                mediaRecorder = { stream, processor, source };-->
<!--                isListening = true;-->
<!--                updateStatus('Listening... Speak now', 'listening');-->
<!--                console.log('Started listening');-->

<!--            } catch (error) {-->
<!--                console.error('Error starting microphone:', error);-->
<!--                showError('Could not access microphone: ' + error.message);-->
<!--            }-->
<!--        }-->

<!--        function stopListening() {-->
<!--            if (mediaRecorder) {-->
<!--                console.log('Stopping microphone');-->
<!--                mediaRecorder.stream.getTracks().forEach(track => track.stop());-->
<!--                mediaRecorder.processor.disconnect();-->
<!--                mediaRecorder.source.disconnect();-->
<!--                if (audioContext) {-->
<!--                    audioContext.close();-->
<!--                    audioContext = null;-->
<!--                }-->
<!--                mediaRecorder = null;-->
<!--            }-->
<!--            isListening = false;-->
<!--            updateStatus('Stopped - Click to start again', '');-->
<!--        }-->

<!--        micButton.addEventListener('click', async () => {-->
<!--            try {-->
<!--                if (!websocket || websocket.readyState !== WebSocket.OPEN) {-->
<!--                    updateStatus('Connecting...', 'processing');-->
<!--                    await connectWebSocket();-->
<!--                    // Wait a moment for welcome message-->
<!--                    await new Promise(resolve => setTimeout(resolve, 1500));-->
<!--                    await startListening();-->
<!--                } else if (isListening) {-->
<!--                    stopListening();-->
<!--                } else {-->
<!--                    await startListening();-->
<!--                }-->
<!--            } catch (error) {-->
<!--                console.error('Error:', error);-->
<!--                showError('Failed to connect or start microphone: ' + error.message);-->
<!--                updateStatus('Error - Click to retry', '');-->
<!--            }-->
<!--        });-->

<!--        clearBtn.addEventListener('click', () => {-->
<!--            conversation.innerHTML = '<span class="transcript-label">Conversation:</span>';-->
<!--            if (websocket && websocket.readyState === WebSocket.OPEN) {-->
<!--                websocket.close();-->
<!--            }-->
<!--            websocket = null;-->
<!--            stopListening();-->
<!--            audioQueue = [];-->
<!--            isPlayingAudio = false;-->
<!--            updateStatus('Click microphone to start', '');-->
<!--        });-->

<!--        // Cleanup on page unload-->
<!--        window.addEventListener('beforeunload', () => {-->
<!--            if (websocket) {-->
<!--                websocket.close();-->
<!--            }-->
<!--            stopListening();-->
<!--        });-->
<!--    </script>-->
<!--</body>-->
<!--</html>-->

<!--new voice ui generated by chatgpt-->

<!--<!DOCTYPE html>-->
<!--<html lang="en">-->
<!--<head>-->
<!--<meta charset="UTF-8" />-->
<!--<meta name="viewport" content="width=device-width, initial-scale=1.0"/>-->
<!--<title>Medilligence ‚Ä¢ Voice Assistant</title>-->

<!--<style>-->
<!--* { margin: 0; padding: 0; box-sizing: border-box; }-->

<!--body {-->
<!--    font-family: "Segoe UI", system-ui, sans-serif;-->
<!--    background: #f4f7fb;-->
<!--    height: 100vh;-->
<!--    display: flex;-->
<!--    justify-content: center;-->
<!--    align-items: center;-->
<!--}-->

<!--/* Container */-->
<!--.voice-container {-->
<!--    width: 100%;-->
<!--    max-width: 820px;-->
<!--    height: 92vh;-->
<!--    background: #ffffff;-->
<!--    border-radius: 18px;-->
<!--    box-shadow: 0 18px 40px rgba(0,0,0,0.12);-->
<!--    display: flex;-->
<!--    flex-direction: column;-->
<!--    overflow: hidden;-->
<!--}-->

<!--/* Header */-->
<!--.voice-header {-->
<!--    background: #2563eb;-->
<!--    color: white;-->
<!--    padding: 16px 20px;-->
<!--    display: flex;-->
<!--    align-items: center;-->
<!--    gap: 12px;-->
<!--}-->

<!--.voice-header .back {-->
<!--    cursor: pointer;-->
<!--    font-size: 18px;-->
<!--}-->

<!--.voice-header h1 {-->
<!--    font-size: 18px;-->
<!--    font-weight: 600;-->
<!--}-->

<!--.voice-header p {-->
<!--    font-size: 12px;-->
<!--    opacity: 0.9;-->
<!--}-->

<!--/* Chat */-->
<!--.voice-messages {-->
<!--    flex: 1;-->
<!--    padding: 20px;-->
<!--    background: #f9fafb;-->
<!--    overflow-y: auto;-->
<!--}-->

<!--.message {-->
<!--    display: flex;-->
<!--    margin-bottom: 14px;-->
<!--}-->

<!--.message.user { justify-content: flex-end; }-->
<!--.message.assistant { justify-content: flex-start; }-->

<!--.bubble {-->
<!--    max-width: 70%;-->
<!--    padding: 12px 16px;-->
<!--    border-radius: 16px;-->
<!--    font-size: 14px;-->
<!--    line-height: 1.5;-->
<!--}-->

<!--.message.user .bubble {-->
<!--    background: #2563eb;-->
<!--    color: white;-->
<!--    border-bottom-right-radius: 4px;-->
<!--}-->

<!--.message.assistant .bubble {-->
<!--    background: #eef2f7;-->
<!--    color: #1f2937;-->
<!--    border-bottom-left-radius: 4px;-->
<!--}-->

<!--/* Voice Bar */-->
<!--.voice-bar {-->
<!--    border-top: 1px solid #e5e7eb;-->
<!--    padding: 14px 18px;-->
<!--    display: flex;-->
<!--    align-items: center;-->
<!--    gap: 14px;-->
<!--    background: #ffffff;-->
<!--}-->

<!--.chat-icon {-->
<!--    width: 42px;-->
<!--    height: 42px;-->
<!--    border-radius: 50%;-->
<!--    border: none;-->
<!--    background: #e0e7ff;-->
<!--    color: #2563eb;-->
<!--    font-size: 18px;-->
<!--    cursor: pointer;-->

<!--    display: flex;-->
<!--    align-items: center;      /* vertical center */-->
<!--    justify-content: center;-->
<!--}-->

<!--.mic-area {-->
<!--    flex: 1;-->
<!--    background: #f3f4f6;-->
<!--    border-radius: 28px;-->
<!--    padding: 10px 16px;-->
<!--    display: flex;-->
<!--    align-items: center;-->
<!--    justify-content: center;-->
<!--    gap: 10px;-->
<!--    cursor: pointer;-->
<!--}-->

<!--.mic {-->
<!--    width: 44px;-->
<!--    height: 44px;-->
<!--    border-radius: 50%;-->
<!--    background: #2563eb;-->
<!--    color: white;-->
<!--    font-size: 20px;-->
<!--    display: flex;-->
<!--    align-items: center;-->
<!--    justify-content: center;-->
<!--}-->

<!--.mic.listening {-->
<!--    animation: pulse 1.4s infinite;-->
<!--}-->

<!--@keyframes pulse {-->
<!--    0% { box-shadow: 0 0 0 0 rgba(37,99,235,0.6); }-->
<!--    70% { box-shadow: 0 0 0 14px rgba(37,99,235,0); }-->
<!--    100% { box-shadow: 0 0 0 0 rgba(37,99,235,0); }-->
<!--}-->

<!--.status {-->
<!--    font-size: 13px;-->
<!--    color: #374151;-->
<!--}-->

<!--/* Clear */-->
<!--.clear-btn {-->
<!--    font-size: 12px;-->
<!--    background: none;-->
<!--    border: none;-->
<!--    color: #6b7280;-->
<!--    cursor: pointer;-->
<!--    padding: 10px;-->
<!--}-->
<!--</style>-->
<!--</head>-->

<!--<body>-->

<!--<div class="voice-container">-->

<!--    &lt;!&ndash; Header &ndash;&gt;-->
<!--    <div class="voice-header">-->
<!--        <div class="back" onclick="goToText()">üí¨</div>-->
<!--        <div>-->
<!--            <h1>Medilligence</h1>-->
<!--            <p>Voice Assistant ‚Ä¢ Manage appointments</p>-->
<!--        </div>-->
<!--    </div>-->

<!--    &lt;!&ndash; Messages &ndash;&gt;-->
<!--    <div class="voice-messages" id="chat">-->
<!--        <div class="message assistant">-->
<!--            <div class="bubble">-->
<!--                Hello! I‚Äôm your medical appointment assistant. How can I help you today?-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->

<!--    &lt;!&ndash; Voice Bar &ndash;&gt;-->
<!--    <div class="voice-bar">-->
<!--        <button class="chat-icon" onclick="goToText()">üí¨</button>-->

<!--        <div class="mic-area" id="micButton">-->
<!--            <div class="mic" id="micIcon">üé§</div>-->
<!--            <div class="status" id="status">Tap to speak</div>-->
<!--        </div>-->

<!--        <button class="clear-btn" id="clearBtn">Clear</button>-->
<!--    </div>-->

<!--</div>-->

<!--<script>-->
<!--/* ========= Navigation ========= */-->
<!--function goToText() {-->
<!--    window.location.href = "./";-->
<!--}-->

<!--/* ========= Chat Helpers ========= */-->
<!--const chat = document.getElementById("chat");-->
<!--const statusEl = document.getElementById("status");-->
<!--const micIcon = document.getElementById("micIcon");-->
<!--const micButton = document.getElementById("micButton");-->
<!--const clearBtn = document.getElementById("clearBtn");-->

<!--let websocket = null;-->
<!--let isListening = false;-->

<!--function addMessage(text, isUser) {-->
<!--    const msg = document.createElement("div");-->
<!--    msg.className = "message " + (isUser ? "user" : "assistant");-->

<!--    const bubble = document.createElement("div");-->
<!--    bubble.className = "bubble";-->
<!--    bubble.textContent = text;-->

<!--    msg.appendChild(bubble);-->
<!--    chat.appendChild(msg);-->
<!--    chat.scrollTop = chat.scrollHeight;-->
<!--}-->

<!--function updateStatus(text, listening=false) {-->
<!--    statusEl.textContent = text;-->
<!--    micIcon.classList.toggle("listening", listening);-->
<!--}-->

<!--/* ========= Mic Click ========= */-->
<!--micButton.addEventListener("click", async () => {-->
<!--    if (!websocket) {-->
<!--        updateStatus("Connecting...");-->
<!--        connectWebSocket();-->
<!--        return;-->
<!--    }-->

<!--    if (isListening) {-->
<!--        stopListening();-->
<!--    } else {-->
<!--        startListening();-->
<!--    }-->
<!--});-->

<!--/* ========= WebSocket (kept same logic) ========= */-->
<!--function connectWebSocket() {-->
<!--    const protocol = location.protocol === "https:" ? "wss:" : "ws:";-->
<!--&lt;!&ndash;    websocket = new WebSocket(`${protocol}//${location.host}/api/voice/ws`);&ndash;&gt;-->
<!--    const pathParts = location.pathname.split('/').filter(p => p);-->
<!--    const basePath = pathParts.length > 0 ? `/${pathParts[0]}` : '';-->

<!--    websocket = new WebSocket(`${protocol}//${location.host}${basePath}/api/voice/ws`);-->

<!--    websocket.onopen = () => {-->
<!--        updateStatus("Listening‚Ä¶", true);-->
<!--        startListening();-->
<!--    };-->

<!--    websocket.onmessage = (e) => {-->
<!--        const data = JSON.parse(e.data);-->
<!--        if (data.type === "transcript") addMessage(data.text, true);-->
<!--        if (data.type === "response") addMessage(data.text, false);-->
<!--    };-->

<!--    websocket.onclose = () => {-->
<!--        websocket = null;-->
<!--        updateStatus("Tap to speak");-->
<!--    };-->
<!--}-->

<!--function startListening() {-->
<!--    isListening = true;-->
<!--    updateStatus("Listening‚Ä¶", true);-->
<!--}-->

<!--function stopListening() {-->
<!--    isListening = false;-->
<!--    updateStatus("Tap to speak");-->
<!--}-->

<!--clearBtn.onclick = () => {-->
<!--    chat.innerHTML = "";-->
<!--    updateStatus("Tap to speak");-->
<!--};-->
<!--</script>-->

<!--</body>-->
<!--</html>-->


<!--new ui generated by claude-->

<!--<!DOCTYPE html>-->
<!--<html lang="en">-->
<!--<head>-->
<!--<meta charset="UTF-8" />-->
<!--<meta name="viewport" content="width=device-width, initial-scale=1.0"/>-->
<!--<title>Medilligence ‚Ä¢ Voice Assistant</title>-->

<!--<style>-->
<!--* { margin: 0; padding: 0; box-sizing: border-box; }-->

<!--body {-->
<!--    font-family: "Segoe UI", system-ui, sans-serif;-->
<!--    background: #f4f7fb;-->
<!--    height: 100vh;-->
<!--    display: flex;-->
<!--    justify-content: center;-->
<!--    align-items: center;-->
<!--}-->

<!--.voice-container {-->
<!--    width: 100%;-->
<!--    max-width: 820px;-->
<!--    height: 92vh;-->
<!--    background: #ffffff;-->
<!--    border-radius: 18px;-->
<!--    box-shadow: 0 18px 40px rgba(0,0,0,0.12);-->
<!--    display: flex;-->
<!--    flex-direction: column;-->
<!--    overflow: hidden;-->
<!--}-->

<!--.voice-header {-->
<!--    background: #2563eb;-->
<!--    color: white;-->
<!--    padding: 16px 20px;-->
<!--    display: flex;-->
<!--    align-items: center;-->
<!--    gap: 12px;-->
<!--}-->

<!--.voice-header .back {-->
<!--    cursor: pointer;-->
<!--    font-size: 18px;-->
<!--}-->

<!--.voice-header h1 {-->
<!--    font-size: 18px;-->
<!--    font-weight: 600;-->
<!--}-->

<!--.voice-header p {-->
<!--    font-size: 12px;-->
<!--    opacity: 0.9;-->
<!--}-->

<!--.voice-messages {-->
<!--    flex: 1;-->
<!--    padding: 20px;-->
<!--    background: #f9fafb;-->
<!--    overflow-y: auto;-->
<!--}-->

<!--.message {-->
<!--    display: flex;-->
<!--    margin-bottom: 14px;-->
<!--}-->

<!--.message.user { justify-content: flex-end; }-->
<!--.message.assistant { justify-content: flex-start; }-->

<!--.bubble {-->
<!--    max-width: 70%;-->
<!--    padding: 12px 16px;-->
<!--    border-radius: 16px;-->
<!--    font-size: 14px;-->
<!--    line-height: 1.5;-->
<!--}-->

<!--.message.user .bubble {-->
<!--    background: #2563eb;-->
<!--    color: white;-->
<!--    border-bottom-right-radius: 4px;-->
<!--}-->

<!--.message.assistant .bubble {-->
<!--    background: #eef2f7;-->
<!--    color: #1f2937;-->
<!--    border-bottom-left-radius: 4px;-->
<!--}-->

<!--.voice-bar {-->
<!--    border-top: 1px solid #e5e7eb;-->
<!--    padding: 14px 18px;-->
<!--    display: flex;-->
<!--    align-items: center;-->
<!--    gap: 14px;-->
<!--    background: #ffffff;-->
<!--}-->

<!--.chat-icon {-->
<!--    width: 42px;-->
<!--    height: 42px;-->
<!--    border-radius: 50%;-->
<!--    border: none;-->
<!--    background: #e0e7ff;-->
<!--    color: #2563eb;-->
<!--    font-size: 18px;-->
<!--    cursor: pointer;-->
<!--    display: flex;-->
<!--    align-items: center;-->
<!--    justify-content: center;-->
<!--}-->

<!--.mic-area {-->
<!--    flex: 1;-->
<!--    background: #f3f4f6;-->
<!--    border-radius: 28px;-->
<!--    padding: 10px 16px;-->
<!--    display: flex;-->
<!--    align-items: center;-->
<!--    justify-content: center;-->
<!--    gap: 10px;-->
<!--    cursor: pointer;-->
<!--}-->

<!--.mic {-->
<!--    width: 44px;-->
<!--    height: 44px;-->
<!--    border-radius: 50%;-->
<!--    background: #2563eb;-->
<!--    color: white;-->
<!--    font-size: 20px;-->
<!--    display: flex;-->
<!--    align-items: center;-->
<!--    justify-content: center;-->
<!--}-->

<!--.mic.listening {-->
<!--    animation: pulse 1.4s infinite;-->
<!--}-->

<!--@keyframes pulse {-->
<!--    0% { box-shadow: 0 0 0 0 rgba(37,99,235,0.6); }-->
<!--    70% { box-shadow: 0 0 0 14px rgba(37,99,235,0); }-->
<!--    100% { box-shadow: 0 0 0 0 rgba(37,99,235,0); }-->
<!--}-->

<!--.status {-->
<!--    font-size: 13px;-->
<!--    color: #374151;-->
<!--}-->

<!--.clear-btn {-->
<!--    font-size: 12px;-->
<!--    background: none;-->
<!--    border: none;-->
<!--    color: #6b7280;-->
<!--    cursor: pointer;-->
<!--    padding: 10px;-->
<!--}-->
<!--</style>-->
<!--</head>-->

<!--<body>-->

<!--<div class="voice-container">-->
<!--    <div class="voice-header">-->
<!--        <div class="back" onclick="goToText()">üí¨</div>-->
<!--        <div>-->
<!--            <h1>Medilligence</h1>-->
<!--            <p>Voice Assistant ‚Ä¢ Manage appointments</p>-->
<!--        </div>-->
<!--    </div>-->

<!--    <div class="voice-messages" id="chat">-->
<!--        <div class="message assistant">-->
<!--            <div class="bubble">-->
<!--                Hello! I'm your medical appointment assistant. How can I help you today?-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->

<!--    <div class="voice-bar">-->
<!--        <button class="chat-icon" onclick="goToText()">üí¨</button>-->

<!--        <div class="mic-area" id="micButton">-->
<!--            <div class="mic" id="micIcon">üé§</div>-->
<!--            <div class="status" id="status">Tap to speak</div>-->
<!--        </div>-->

<!--        <button class="clear-btn" id="clearBtn">Clear</button>-->
<!--    </div>-->
<!--</div>-->

<!--&lt;!&ndash;<script>&ndash;&gt;-->
<!--&lt;!&ndash;function goToText() {&ndash;&gt;-->
<!--&lt;!&ndash;    window.location.href = "./";&ndash;&gt;-->
<!--&lt;!&ndash;}&ndash;&gt;-->

<!--&lt;!&ndash;const chat = document.getElementById("chat");&ndash;&gt;-->
<!--&lt;!&ndash;const statusEl = document.getElementById("status");&ndash;&gt;-->
<!--&lt;!&ndash;const micIcon = document.getElementById("micIcon");&ndash;&gt;-->
<!--&lt;!&ndash;const micButton = document.getElementById("micButton");&ndash;&gt;-->
<!--&lt;!&ndash;const clearBtn = document.getElementById("clearBtn");&ndash;&gt;-->

<!--&lt;!&ndash;let websocket = null;&ndash;&gt;-->
<!--&lt;!&ndash;let isListening = false;&ndash;&gt;-->
<!--&lt;!&ndash;let mediaRecorder = null;&ndash;&gt;-->
<!--&lt;!&ndash;let audioContext = null;&ndash;&gt;-->
<!--&lt;!&ndash;let audioQueue = [];&ndash;&gt;-->
<!--&lt;!&ndash;let isPlayingAudio = false;&ndash;&gt;-->

<!--&lt;!&ndash;function addMessage(text, isUser) {&ndash;&gt;-->
<!--&lt;!&ndash;    const msg = document.createElement("div");&ndash;&gt;-->
<!--&lt;!&ndash;    msg.className = "message " + (isUser ? "user" : "assistant");&ndash;&gt;-->

<!--&lt;!&ndash;    const bubble = document.createElement("div");&ndash;&gt;-->
<!--&lt;!&ndash;    bubble.className = "bubble";&ndash;&gt;-->
<!--&lt;!&ndash;    bubble.textContent = text;&ndash;&gt;-->

<!--&lt;!&ndash;    msg.appendChild(bubble);&ndash;&gt;-->
<!--&lt;!&ndash;    chat.appendChild(msg);&ndash;&gt;-->
<!--&lt;!&ndash;    chat.scrollTop = chat.scrollHeight;&ndash;&gt;-->
<!--&lt;!&ndash;}&ndash;&gt;-->

<!--&lt;!&ndash;function updateStatus(text, listening=false) {&ndash;&gt;-->
<!--&lt;!&ndash;    statusEl.textContent = text;&ndash;&gt;-->
<!--&lt;!&ndash;    micIcon.classList.toggle("listening", listening);&ndash;&gt;-->
<!--&lt;!&ndash;}&ndash;&gt;-->

<!--&lt;!&ndash;// Initialize audio context&ndash;&gt;-->
<!--&lt;!&ndash;async function initAudio() {&ndash;&gt;-->
<!--&lt;!&ndash;    try {&ndash;&gt;-->
<!--&lt;!&ndash;        audioContext = new (window.AudioContext || window.webkitAudioContext)();&ndash;&gt;-->
<!--&lt;!&ndash;        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });&ndash;&gt;-->

<!--&lt;!&ndash;&lt;!&ndash;        mediaRecorder = new MediaRecorder(stream, {&ndash;&gt;&ndash;&gt;-->
<!--&lt;!&ndash;&lt;!&ndash;            mimeType: 'audio/webm'&ndash;&gt;&ndash;&gt;-->
<!--&lt;!&ndash;&lt;!&ndash;        });&ndash;&gt;&ndash;&gt;-->
<!--&lt;!&ndash;        mediaRecorder = new MediaRecorder(stream, {&ndash;&gt;-->
<!--&lt;!&ndash;            mimeType: 'audio/webm;codecs=opus'&ndash;&gt;-->
<!--&lt;!&ndash;        });&ndash;&gt;-->


<!--&lt;!&ndash;        mediaRecorder.ondataavailable = (event) => {&ndash;&gt;-->
<!--&lt;!&ndash;            if (event.data.size > 0 && websocket && websocket.readyState === WebSocket.OPEN) {&ndash;&gt;-->
<!--&lt;!&ndash;                websocket.send(event.data);&ndash;&gt;-->
<!--&lt;!&ndash;            }&ndash;&gt;-->
<!--&lt;!&ndash;        };&ndash;&gt;-->

<!--&lt;!&ndash;        return true;&ndash;&gt;-->
<!--&lt;!&ndash;    } catch (error) {&ndash;&gt;-->
<!--&lt;!&ndash;        console.error('Error accessing microphone:', error);&ndash;&gt;-->
<!--&lt;!&ndash;        updateStatus('Microphone access denied');&ndash;&gt;-->
<!--&lt;!&ndash;        return false;&ndash;&gt;-->
<!--&lt;!&ndash;    }&ndash;&gt;-->
<!--&lt;!&ndash;}&ndash;&gt;-->

<!--&lt;!&ndash;micButton.addEventListener("click", async () => {&ndash;&gt;-->
<!--&lt;!&ndash;    if (!websocket) {&ndash;&gt;-->
<!--&lt;!&ndash;        updateStatus("Connecting...");&ndash;&gt;-->
<!--&lt;!&ndash;        await connectWebSocket();&ndash;&gt;-->
<!--&lt;!&ndash;        return;&ndash;&gt;-->
<!--&lt;!&ndash;    }&ndash;&gt;-->

<!--&lt;!&ndash;    if (isListening) {&ndash;&gt;-->
<!--&lt;!&ndash;        stopListening();&ndash;&gt;-->
<!--&lt;!&ndash;    } else {&ndash;&gt;-->
<!--&lt;!&ndash;        startListening();&ndash;&gt;-->
<!--&lt;!&ndash;    }&ndash;&gt;-->
<!--&lt;!&ndash;});&ndash;&gt;-->

<!--&lt;!&ndash;async function connectWebSocket() {&ndash;&gt;-->
<!--&lt;!&ndash;    // Initialize audio first&ndash;&gt;-->
<!--&lt;!&ndash;    const audioInitialized = await initAudio();&ndash;&gt;-->
<!--&lt;!&ndash;    if (!audioInitialized) return;&ndash;&gt;-->

<!--&lt;!&ndash;    const protocol = location.protocol === "https:" ? "wss:" : "ws:";&ndash;&gt;-->
<!--&lt;!&ndash;    const pathParts = location.pathname.split('/').filter(p => p);&ndash;&gt;-->
<!--&lt;!&ndash;    const basePath = pathParts.length > 0 ? `/${pathParts[0]}` : '';&ndash;&gt;-->

<!--&lt;!&ndash;    const wsUrl = `${protocol}//${location.host}${basePath}/api/voice/ws`;&ndash;&gt;-->
<!--&lt;!&ndash;    console.log('Connecting to WebSocket:', wsUrl);&ndash;&gt;-->

<!--&lt;!&ndash;    websocket = new WebSocket(wsUrl);&ndash;&gt;-->

<!--&lt;!&ndash;    websocket.onopen = () => {&ndash;&gt;-->
<!--&lt;!&ndash;        console.log('WebSocket connected');&ndash;&gt;-->
<!--&lt;!&ndash;        updateStatus("Ready - Tap to speak");&ndash;&gt;-->
<!--&lt;!&ndash;    };&ndash;&gt;-->

<!--&lt;!&ndash;    websocket.onmessage = async (e) => {&ndash;&gt;-->
<!--&lt;!&ndash;        if (e.data instanceof Blob) {&ndash;&gt;-->
<!--&lt;!&ndash;            // Received audio from backend&ndash;&gt;-->
<!--&lt;!&ndash;            console.log('Received audio blob:', e.data.size, 'bytes');&ndash;&gt;-->
<!--&lt;!&ndash;            audioQueue.push(e.data);&ndash;&gt;-->
<!--&lt;!&ndash;            if (!isPlayingAudio) {&ndash;&gt;-->
<!--&lt;!&ndash;                playNextAudio();&ndash;&gt;-->
<!--&lt;!&ndash;            }&ndash;&gt;-->
<!--&lt;!&ndash;        } else {&ndash;&gt;-->
<!--&lt;!&ndash;            // Received text data&ndash;&gt;-->
<!--&lt;!&ndash;            try {&ndash;&gt;-->
<!--&lt;!&ndash;                const data = JSON.parse(e.data);&ndash;&gt;-->
<!--&lt;!&ndash;                console.log('Received message:', data);&ndash;&gt;-->

<!--&lt;!&ndash;                // Handle different message types&ndash;&gt;-->
<!--&lt;!&ndash;                if (data.type === "transcript" || data.type === "user_transcript") {&ndash;&gt;-->
<!--&lt;!&ndash;                    console.log('User transcript:', data.text);&ndash;&gt;-->
<!--&lt;!&ndash;                    addMessage(data.text, true);&ndash;&gt;-->
<!--&lt;!&ndash;                    updateStatus("Processing...");&ndash;&gt;-->
<!--&lt;!&ndash;                }&ndash;&gt;-->
<!--&lt;!&ndash;                else if (data.type === "response" || data.type === "assistant_response") {&ndash;&gt;-->
<!--&lt;!&ndash;                    console.log('Assistant response:', data.text);&ndash;&gt;-->
<!--&lt;!&ndash;                    addMessage(data.text, false);&ndash;&gt;-->
<!--&lt;!&ndash;                }&ndash;&gt;-->
<!--&lt;!&ndash;                else if (data.type === "interim_transcript") {&ndash;&gt;-->
<!--&lt;!&ndash;                    console.log('Interim:', data.text);&ndash;&gt;-->
<!--&lt;!&ndash;                    updateStatus(`Hearing: ${data.text.substring(0, 30)}...`);&ndash;&gt;-->
<!--&lt;!&ndash;                }&ndash;&gt;-->
<!--&lt;!&ndash;                else if (data.type === "status") {&ndash;&gt;-->
<!--&lt;!&ndash;                    console.log('Status:', data.message);&ndash;&gt;-->
<!--&lt;!&ndash;                    updateStatus(data.message);&ndash;&gt;-->
<!--&lt;!&ndash;                }&ndash;&gt;-->
<!--&lt;!&ndash;                else if (data.type === "error") {&ndash;&gt;-->
<!--&lt;!&ndash;                    console.error('Error from backend:', data.message);&ndash;&gt;-->
<!--&lt;!&ndash;                    updateStatus("Error: " + data.message);&ndash;&gt;-->
<!--&lt;!&ndash;                }&ndash;&gt;-->
<!--&lt;!&ndash;                else {&ndash;&gt;-->
<!--&lt;!&ndash;                    console.log('Unknown message type:', data);&ndash;&gt;-->
<!--&lt;!&ndash;                }&ndash;&gt;-->
<!--&lt;!&ndash;            } catch (error) {&ndash;&gt;-->
<!--&lt;!&ndash;                console.error('Error parsing message:', error, e.data);&ndash;&gt;-->
<!--&lt;!&ndash;            }&ndash;&gt;-->
<!--&lt;!&ndash;        }&ndash;&gt;-->
<!--&lt;!&ndash;    };&ndash;&gt;-->

<!--&lt;!&ndash;    websocket.onerror = (error) => {&ndash;&gt;-->
<!--&lt;!&ndash;        console.error('WebSocket error:', error);&ndash;&gt;-->
<!--&lt;!&ndash;        updateStatus("Connection error");&ndash;&gt;-->
<!--&lt;!&ndash;    };&ndash;&gt;-->

<!--&lt;!&ndash;    websocket.onclose = () => {&ndash;&gt;-->
<!--&lt;!&ndash;        console.log('WebSocket closed');&ndash;&gt;-->
<!--&lt;!&ndash;        websocket = null;&ndash;&gt;-->
<!--&lt;!&ndash;        updateStatus("Tap to speak");&ndash;&gt;-->
<!--&lt;!&ndash;    };&ndash;&gt;-->
<!--&lt;!&ndash;}&ndash;&gt;-->

<!--&lt;!&ndash;async function playNextAudio() {&ndash;&gt;-->
<!--&lt;!&ndash;    if (audioQueue.length === 0) {&ndash;&gt;-->
<!--&lt;!&ndash;        isPlayingAudio = false;&ndash;&gt;-->
<!--&lt;!&ndash;        updateStatus("Tap to speak");&ndash;&gt;-->
<!--&lt;!&ndash;        return;&ndash;&gt;-->
<!--&lt;!&ndash;    }&ndash;&gt;-->

<!--&lt;!&ndash;    isPlayingAudio = true;&ndash;&gt;-->
<!--&lt;!&ndash;    updateStatus("Playing response...");&ndash;&gt;-->

<!--&lt;!&ndash;    const audioBlob = audioQueue.shift();&ndash;&gt;-->

<!--&lt;!&ndash;    try {&ndash;&gt;-->
<!--&lt;!&ndash;        const arrayBuffer = await audioBlob.arrayBuffer();&ndash;&gt;-->
<!--&lt;!&ndash;        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);&ndash;&gt;-->

<!--&lt;!&ndash;        const source = audioContext.createBufferSource();&ndash;&gt;-->
<!--&lt;!&ndash;        source.buffer = audioBuffer;&ndash;&gt;-->
<!--&lt;!&ndash;        source.connect(audioContext.destination);&ndash;&gt;-->

<!--&lt;!&ndash;        source.onended = () => {&ndash;&gt;-->
<!--&lt;!&ndash;            playNextAudio();&ndash;&gt;-->
<!--&lt;!&ndash;        };&ndash;&gt;-->

<!--&lt;!&ndash;        source.start(0);&ndash;&gt;-->
<!--&lt;!&ndash;    } catch (error) {&ndash;&gt;-->
<!--&lt;!&ndash;        console.error('Error playing audio:', error);&ndash;&gt;-->
<!--&lt;!&ndash;        playNextAudio();&ndash;&gt;-->
<!--&lt;!&ndash;    }&ndash;&gt;-->
<!--&lt;!&ndash;}&ndash;&gt;-->

<!--&lt;!&ndash;function startListening() {&ndash;&gt;-->
<!--&lt;!&ndash;    if (!mediaRecorder) {&ndash;&gt;-->
<!--&lt;!&ndash;        updateStatus("Microphone not ready");&ndash;&gt;-->
<!--&lt;!&ndash;        return;&ndash;&gt;-->
<!--&lt;!&ndash;    }&ndash;&gt;-->

<!--&lt;!&ndash;    if (mediaRecorder.state === 'inactive') {&ndash;&gt;-->
<!--&lt;!&ndash;        mediaRecorder.start(100); // Send data every 100ms&ndash;&gt;-->
<!--&lt;!&ndash;        isListening = true;&ndash;&gt;-->
<!--&lt;!&ndash;        updateStatus("Listening‚Ä¶", true);&ndash;&gt;-->
<!--&lt;!&ndash;    }&ndash;&gt;-->
<!--&lt;!&ndash;}&ndash;&gt;-->

<!--&lt;!&ndash;function stopListening() {&ndash;&gt;-->
<!--&lt;!&ndash;&lt;!&ndash;    if (mediaRecorder && mediaRecorder.state === 'recording') {&ndash;&gt;&ndash;&gt;-->
<!--&lt;!&ndash;&lt;!&ndash;        mediaRecorder.stop();&ndash;&gt;&ndash;&gt;-->
<!--&lt;!&ndash;&lt;!&ndash;        isListening = false;&ndash;&gt;&ndash;&gt;-->
<!--&lt;!&ndash;&lt;!&ndash;        updateStatus("Processing...");&ndash;&gt;&ndash;&gt;-->
<!--&lt;!&ndash;&lt;!&ndash;    }&ndash;&gt;&ndash;&gt;-->
<!--&lt;!&ndash;    if (mediaRecorder && mediaRecorder.state === 'recording') {&ndash;&gt;-->
<!--&lt;!&ndash;        mediaRecorder.stop();&ndash;&gt;-->
<!--&lt;!&ndash;        isListening = false;&ndash;&gt;-->

<!--&lt;!&ndash;        if (websocket && websocket.readyState === WebSocket.OPEN) {&ndash;&gt;-->
<!--&lt;!&ndash;            websocket.send(JSON.stringify({ type: "stop" }));&ndash;&gt;-->
<!--&lt;!&ndash;        }&ndash;&gt;-->

<!--&lt;!&ndash;        updateStatus("Processing...");&ndash;&gt;-->
<!--&lt;!&ndash;    }&ndash;&gt;-->
<!--&lt;!&ndash;}&ndash;&gt;-->

<!--&lt;!&ndash;clearBtn.onclick = () => {&ndash;&gt;-->
<!--&lt;!&ndash;    chat.innerHTML = `&ndash;&gt;-->
<!--&lt;!&ndash;        <div class="message assistant">&ndash;&gt;-->
<!--&lt;!&ndash;            <div class="bubble">&ndash;&gt;-->
<!--&lt;!&ndash;                Hello! I'm your medical appointment assistant. How can I help you today?&ndash;&gt;-->
<!--&lt;!&ndash;            </div>&ndash;&gt;-->
<!--&lt;!&ndash;        </div>&ndash;&gt;-->
<!--&lt;!&ndash;    `;&ndash;&gt;-->
<!--&lt;!&ndash;    updateStatus("Tap to speak");&ndash;&gt;-->
<!--&lt;!&ndash;};&ndash;&gt;-->

<!--&lt;!&ndash;// Cleanup on page unload&ndash;&gt;-->
<!--&lt;!&ndash;window.addEventListener('beforeunload', () => {&ndash;&gt;-->
<!--&lt;!&ndash;    if (websocket) {&ndash;&gt;-->
<!--&lt;!&ndash;        websocket.close();&ndash;&gt;-->
<!--&lt;!&ndash;    }&ndash;&gt;-->
<!--&lt;!&ndash;    if (mediaRecorder && mediaRecorder.state === 'recording') {&ndash;&gt;-->
<!--&lt;!&ndash;        mediaRecorder.stop();&ndash;&gt;-->
<!--&lt;!&ndash;    }&ndash;&gt;-->
<!--&lt;!&ndash;});&ndash;&gt;-->
<!--&lt;!&ndash;</script>&ndash;&gt;-->

<!--<script>-->
<!--function goToText() {-->
<!--    window.location.href = "./";-->
<!--}-->

<!--const chat = document.getElementById("chat");-->
<!--const statusEl = document.getElementById("status");-->
<!--const micIcon = document.getElementById("micIcon");-->
<!--const micButton = document.getElementById("micButton");-->
<!--const clearBtn = document.getElementById("clearBtn");-->

<!--let websocket = null;-->
<!--let isListening = false;-->
<!--let mediaRecorder = null;-->
<!--let audioContext = null;-->
<!--let audioQueue = [];-->
<!--let isPlayingAudio = false;-->

<!--/* &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; UI helpers &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; */-->

<!--function addMessage(text, isUser) {-->
<!--    const msg = document.createElement("div");-->
<!--    msg.className = "message " + (isUser ? "user" : "assistant");-->

<!--    const bubble = document.createElement("div");-->
<!--    bubble.className = "bubble";-->
<!--    bubble.textContent = text;-->

<!--    msg.appendChild(bubble);-->
<!--    chat.appendChild(msg);-->
<!--    chat.scrollTop = chat.scrollHeight;-->
<!--}-->

<!--function updateStatus(text, listening = false) {-->
<!--    statusEl.textContent = text;-->
<!--    micIcon.classList.toggle("listening", listening);-->
<!--}-->

<!--/* &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; Audio init (FAO style) &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; */-->

<!--async function initAudio() {-->
<!--    try {-->
<!--        audioContext = new (window.AudioContext || window.webkitAudioContext)();-->
<!--        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });-->

<!--        // SAME as patient_fao_agent-->
<!--        mediaRecorder = new MediaRecorder(stream, {-->
<!--            mimeType: "audio/webm"-->
<!--        });-->

<!--        mediaRecorder.ondataavailable = (event) => {-->
<!--            if (-->
<!--                event.data.size > 0 &&-->
<!--                websocket &&-->
<!--                websocket.readyState === WebSocket.OPEN-->
<!--            ) {-->
<!--                websocket.send(event.data);-->
<!--            }-->
<!--        };-->

<!--        return true;-->
<!--    } catch (error) {-->
<!--        console.error("Error accessing microphone:", error);-->
<!--        updateStatus("Microphone access denied");-->
<!--        return false;-->
<!--    }-->
<!--}-->

<!--/* &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; Mic click &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; */-->

<!--micButton.addEventListener("click", async () => {-->
<!--    if (!websocket) {-->
<!--        updateStatus("Connecting...");-->
<!--        await connectWebSocket();-->
<!--        return;-->
<!--    }-->

<!--    isListening ? stopListening() : startListening();-->
<!--});-->

<!--/* &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; WebSocket &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; */-->

<!--async function connectWebSocket() {-->
<!--    const audioInitialized = await initAudio();-->
<!--    if (!audioInitialized) return;-->

<!--    const protocol = location.protocol === "https:" ? "wss:" : "ws:";-->
<!--    const pathParts = location.pathname.split("/").filter(Boolean);-->
<!--    const basePath = pathParts.length > 0 ? `/${pathParts[0]}` : "";-->

<!--    const wsUrl = `${protocol}//${location.host}${basePath}/api/voice/ws`;-->
<!--    console.log("Connecting to WebSocket:", wsUrl);-->

<!--    websocket = new WebSocket(wsUrl);-->

<!--    websocket.onopen = () => {-->
<!--        console.log("WebSocket connected");-->
<!--        updateStatus("Ready - Tap to speak");-->
<!--    };-->

<!--    websocket.onmessage = async (e) => {-->
<!--        if (e.data instanceof Blob) {-->
<!--            audioQueue.push(e.data);-->
<!--            if (!isPlayingAudio) playNextAudio();-->
<!--            return;-->
<!--        }-->

<!--        try {-->
<!--            const data = JSON.parse(e.data);-->
<!--            console.log("Received:", data);-->

<!--            switch (data.type) {-->
<!--                case "transcript":-->
<!--                    addMessage(data.text, true);-->
<!--                    updateStatus("Processing...");-->
<!--                    break;-->

<!--                case "response":-->
<!--                    addMessage(data.text, false);-->
<!--                    break;-->

<!--                case "interim_transcript":-->
<!--                    updateStatus("Listening‚Ä¶", true);-->
<!--                    break;-->

<!--                case "status":-->
<!--                    updateStatus(data.message);-->
<!--                    break;-->

<!--                case "error":-->
<!--                    console.error(data.message);-->
<!--                    updateStatus("Error: " + data.message);-->
<!--                    break;-->
<!--            }-->
<!--        } catch (err) {-->
<!--            console.error("WS parse error:", err);-->
<!--        }-->
<!--    };-->

<!--    websocket.onerror = (err) => {-->
<!--        console.error("WebSocket error:", err);-->
<!--        updateStatus("Connection error");-->
<!--    };-->

<!--    websocket.onclose = () => {-->
<!--        websocket = null;-->
<!--        updateStatus("Tap to speak");-->
<!--    };-->
<!--}-->

<!--/* &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; Audio playback &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; */-->

<!--async function playNextAudio() {-->
<!--    if (!audioQueue.length) {-->
<!--        isPlayingAudio = false;-->
<!--        updateStatus("Tap to speak");-->
<!--        return;-->
<!--    }-->

<!--    isPlayingAudio = true;-->
<!--    updateStatus("Playing response...");-->

<!--    const audioBlob = audioQueue.shift();-->

<!--    try {-->
<!--        const buffer = await audioBlob.arrayBuffer();-->
<!--        const audio = await audioContext.decodeAudioData(buffer);-->

<!--        const source = audioContext.createBufferSource();-->
<!--        source.buffer = audio;-->
<!--        source.connect(audioContext.destination);-->

<!--        source.onended = playNextAudio;-->
<!--        source.start();-->
<!--    } catch (err) {-->
<!--        console.error("Audio play error:", err);-->
<!--        playNextAudio();-->
<!--    }-->
<!--}-->

<!--/* &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; Recording control &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; */-->

<!--function startListening() {-->
<!--    if (!mediaRecorder || mediaRecorder.state !== "inactive") return;-->

<!--    mediaRecorder.start(100);-->
<!--    isListening = true;-->
<!--    updateStatus("Listening‚Ä¶", true);-->
<!--}-->

<!--function stopListening() {-->
<!--    if (!mediaRecorder || mediaRecorder.state !== "recording") return;-->

<!--    // IMPORTANT: no "stop" message to backend (FAO flow)-->
<!--    mediaRecorder.stop();-->
<!--    isListening = false;-->
<!--    updateStatus("Processing...");-->
<!--}-->

<!--/* &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; Clear chat &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; */-->

<!--clearBtn.onclick = () => {-->
<!--    chat.innerHTML = `-->
<!--        <div class="message assistant">-->
<!--            <div class="bubble">-->
<!--                Hello! I'm your medical appointment assistant. How can I help you today?-->
<!--            </div>-->
<!--        </div>-->
<!--    `;-->
<!--    updateStatus("Tap to speak");-->
<!--};-->

<!--/* &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; Cleanup &#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45; */-->

<!--window.addEventListener("beforeunload", () => {-->
<!--    if (websocket) websocket.close();-->
<!--    if (mediaRecorder && mediaRecorder.state === "recording") {-->
<!--        mediaRecorder.stop();-->
<!--    }-->
<!--});-->
<!--</script>-->

<!--</body>-->
<!--</html>-->

<!--new version generated by claude for deepgram sdk transmission-->

<!--<!DOCTYPE html>-->
<!--<html lang="en">-->
<!--<head>-->
<!--    <meta charset="UTF-8">-->
<!--    <meta name="viewport" content="width=device-width, initial-scale=1.0">-->
<!--    <title>Voice Medical Appointment Assistant - Powered by Deepgram SDK</title>-->
<!--    <style>-->
<!--        * {-->
<!--            margin: 0;-->
<!--            padding: 0;-->
<!--            box-sizing: border-box;-->
<!--        }-->

<!--        body {-->
<!--            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            height: 100vh;-->
<!--            display: flex;-->
<!--            justify-content: center;-->
<!--            align-items: center;-->
<!--            padding: 20px;-->
<!--        }-->

<!--        .voice-container {-->
<!--            width: 100%;-->
<!--            max-width: 800px;-->
<!--            background: white;-->
<!--            border-radius: 20px;-->
<!--            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);-->
<!--            padding: 40px;-->
<!--            text-align: center;-->
<!--        }-->

<!--        .header {-->
<!--            margin-bottom: 30px;-->
<!--        }-->

<!--        .header h1 {-->
<!--            font-size: 32px;-->
<!--            color: #667eea;-->
<!--            margin-bottom: 10px;-->
<!--        }-->

<!--        .header p {-->
<!--            color: #666;-->
<!--            font-size: 16px;-->
<!--        }-->

<!--        .mode-toggle {-->
<!--            display: flex;-->
<!--            justify-content: center;-->
<!--            gap: 10px;-->
<!--            margin-bottom: 30px;-->
<!--        }-->

<!--        .mode-btn {-->
<!--            padding: 10px 20px;-->
<!--            border: 2px solid #667eea;-->
<!--            background: white;-->
<!--            color: #667eea;-->
<!--            border-radius: 25px;-->
<!--            cursor: pointer;-->
<!--            font-size: 14px;-->
<!--            font-weight: 600;-->
<!--            transition: all 0.3s;-->
<!--        }-->

<!--        .mode-btn.active {-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            color: white;-->
<!--        }-->

<!--        .mode-btn:hover {-->
<!--            transform: translateY(-2px);-->
<!--            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);-->
<!--        }-->

<!--        .microphone-wrapper {-->
<!--            margin: 40px 0;-->
<!--        }-->

<!--        .microphone-button {-->
<!--            width: 120px;-->
<!--            height: 120px;-->
<!--            border-radius: 50%;-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            border: none;-->
<!--            cursor: pointer;-->
<!--            display: inline-flex;-->
<!--            align-items: center;-->
<!--            justify-content: center;-->
<!--            transition: all 0.3s;-->
<!--            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);-->
<!--        }-->

<!--        .microphone-button:hover {-->
<!--            transform: scale(1.1);-->
<!--            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.6);-->
<!--        }-->

<!--        .microphone-button.listening {-->
<!--            animation: pulse 1.5s infinite;-->
<!--            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);-->
<!--        }-->

<!--        .microphone-button.processing {-->
<!--            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);-->
<!--        }-->

<!--        @keyframes pulse {-->
<!--            0%, 100% {-->
<!--                transform: scale(1);-->
<!--                box-shadow: 0 10px 30px rgba(240, 147, 251, 0.4);-->
<!--            }-->
<!--            50% {-->
<!--                transform: scale(1.1);-->
<!--                box-shadow: 0 15px 40px rgba(240, 147, 251, 0.6);-->
<!--            }-->
<!--        }-->

<!--        .microphone-icon {-->
<!--            font-size: 48px;-->
<!--            color: white;-->
<!--        }-->

<!--        .status {-->
<!--            font-size: 18px;-->
<!--            color: #667eea;-->
<!--            margin: 20px 0;-->
<!--            min-height: 30px;-->
<!--            font-weight: 600;-->
<!--        }-->

<!--        .transcript-section {-->
<!--            margin: 30px 0;-->
<!--            text-align: left;-->
<!--        }-->

<!--        .transcript-box {-->
<!--            background: #f7f7f7;-->
<!--            border-radius: 15px;-->
<!--            padding: 20px;-->
<!--            min-height: 150px;-->
<!--            max-height: 300px;-->
<!--            overflow-y: auto;-->
<!--        }-->

<!--        .transcript-label {-->
<!--            font-weight: 600;-->
<!--            color: #667eea;-->
<!--            margin-bottom: 10px;-->
<!--            display: block;-->
<!--        }-->

<!--        .transcript-text {-->
<!--            color: #333;-->
<!--            line-height: 1.6;-->
<!--            margin-bottom: 15px;-->
<!--        }-->

<!--        .transcript-text.user {-->
<!--            color: #764ba2;-->
<!--            font-weight: 500;-->
<!--        }-->

<!--        .transcript-text.assistant {-->
<!--            color: #667eea;-->
<!--        }-->

<!--        .controls {-->
<!--            display: flex;-->
<!--            justify-content: center;-->
<!--            gap: 15px;-->
<!--            margin-top: 30px;-->
<!--        }-->

<!--        .control-btn {-->
<!--            padding: 12px 24px;-->
<!--            border: none;-->
<!--            border-radius: 25px;-->
<!--            cursor: pointer;-->
<!--            font-size: 14px;-->
<!--            font-weight: 600;-->
<!--            transition: all 0.3s;-->
<!--        }-->

<!--        .control-btn.primary {-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            color: white;-->
<!--        }-->

<!--        .control-btn.secondary {-->
<!--            background: #f44336;-->
<!--            color: white;-->
<!--        }-->

<!--        .control-btn:hover {-->
<!--            transform: translateY(-2px);-->
<!--            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);-->
<!--        }-->

<!--        .control-btn:disabled {-->
<!--            opacity: 0.5;-->
<!--            cursor: not-allowed;-->
<!--            transform: none;-->
<!--        }-->

<!--        .error-message {-->
<!--            background: #ffebee;-->
<!--            color: #c62828;-->
<!--            padding: 15px;-->
<!--            border-radius: 10px;-->
<!--            margin-top: 20px;-->
<!--            display: none;-->
<!--        }-->

<!--        .error-message.show {-->
<!--            display: block;-->
<!--        }-->

<!--        .back-link {-->
<!--            margin-top: 20px;-->
<!--        }-->

<!--        .back-link a {-->
<!--            color: #667eea;-->
<!--            text-decoration: none;-->
<!--            font-weight: 600;-->
<!--        }-->

<!--        .back-link a:hover {-->
<!--            text-decoration: underline;-->
<!--        }-->
<!--    </style>-->
<!--</head>-->
<!--<body>-->
<!--    <div class="voice-container">-->
<!--        <div class="header">-->
<!--            <h1>üé§ Voice Medical Assistant</h1>-->
<!--            <p>Talk to book, cancel, or manage your appointments</p>-->
<!--        </div>-->

<!--        <div class="mode-toggle">-->
<!--            <a href="/" style="text-decoration: none;">-->
<!--                <button class="mode-btn">üí¨ Text Chat</button>-->
<!--            </a>-->
<!--            <button class="mode-btn active">üé§ Voice Chat</button>-->
<!--        </div>-->

<!--        <div class="microphone-wrapper">-->
<!--            <button class="microphone-button" id="micButton">-->
<!--                <span class="microphone-icon">üé§</span>-->
<!--            </button>-->
<!--        </div>-->

<!--        <div class="status" id="status">Click microphone to start</div>-->

<!--        <div class="transcript-section">-->
<!--            <div class="transcript-box" id="transcriptBox">-->
<!--                <span class="transcript-label">Conversation:</span>-->
<!--                <div id="conversation"></div>-->
<!--            </div>-->
<!--        </div>-->

<!--        <div class="controls">-->
<!--            <button class="control-btn secondary" id="clearBtn">Clear Conversation</button>-->
<!--        </div>-->

<!--        <div class="error-message" id="errorMessage"></div>-->

<!--        <div class="back-link">-->
<!--            <a href="/">‚Üê Switch to Text Chat</a>-->
<!--        </div>-->
<!--    </div>-->

<!--    <script>-->
<!--        let websocket = null;-->
<!--        let mediaRecorder = null;-->
<!--        let audioContext = null;-->
<!--        let isListening = false;-->
<!--        let audioQueue = [];-->
<!--        let isPlayingAudio = false;-->

<!--        const micButton = document.getElementById('micButton');-->
<!--        const status = document.getElementById('status');-->
<!--        const conversation = document.getElementById('conversation');-->
<!--        const errorMessage = document.getElementById('errorMessage');-->
<!--        const clearBtn = document.getElementById('clearBtn');-->

<!--        function showError(message) {-->
<!--            errorMessage.textContent = message;-->
<!--            errorMessage.classList.add('show');-->
<!--            setTimeout(() => {-->
<!--                errorMessage.classList.remove('show');-->
<!--            }, 5000);-->
<!--        }-->

<!--        function updateStatus(message, className = '') {-->
<!--            status.textContent = message;-->
<!--            micButton.className = 'microphone-button ' + className;-->
<!--        }-->

<!--        function addToConversation(text, isUser) {-->
<!--            const div = document.createElement('div');-->
<!--            div.className = `transcript-text ${isUser ? 'user' : 'assistant'}`;-->
<!--            div.textContent = `${isUser ? 'You' : 'Assistant'}: ${text}`;-->
<!--            conversation.appendChild(div);-->
<!--            document.getElementById('transcriptBox').scrollTop = document.getElementById('transcriptBox').scrollHeight;-->
<!--        }-->

<!--        async function playAudio(audioData) {-->
<!--            return new Promise((resolve) => {-->
<!--                const audioBlob = new Blob([audioData], { type: 'audio/mpeg' });-->
<!--                const audioUrl = URL.createObjectURL(audioBlob);-->
<!--                const audio = new Audio(audioUrl);-->

<!--                audio.onended = () => {-->
<!--                    URL.revokeObjectURL(audioUrl);-->
<!--                    resolve();-->
<!--                };-->

<!--                audio.onerror = (error) => {-->
<!--                    console.error('Audio playback error:', error);-->
<!--                    resolve();-->
<!--                };-->

<!--                audio.play().catch(error => {-->
<!--                    console.error('Play error:', error);-->
<!--                    resolve();-->
<!--                });-->
<!--            });-->
<!--        }-->

<!--        async function processAudioQueue() {-->
<!--            if (isPlayingAudio || audioQueue.length === 0) return;-->

<!--            isPlayingAudio = true;-->
<!--            const audioData = audioQueue.shift();-->
<!--            await playAudio(audioData);-->
<!--            isPlayingAudio = false;-->

<!--            if (audioQueue.length > 0) {-->
<!--                processAudioQueue();-->
<!--            }-->
<!--        }-->

<!--        async function connectWebSocket() {-->
<!--            return new Promise((resolve, reject) => {-->
<!--                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';-->
<!--&lt;!&ndash;                const wsUrl = `${protocol}//${window.location.host}/api/voice/ws`;&ndash;&gt;-->

<!--                const pathParts = location.pathname.split("/").filter(Boolean);-->
<!--                const basePath = pathParts.length > 0 ? `/${pathParts[0]}` : "";-->

<!--                const wsUrl = `${protocol}//${location.host}${basePath}/api/voice/ws`;-->

<!--                console.log('Connecting to:', wsUrl);-->
<!--                websocket = new WebSocket(wsUrl);-->

<!--                websocket.onopen = () => {-->
<!--                    console.log('WebSocket connected');-->
<!--                    updateStatus('Connected - Ready to listen', '');-->
<!--                    resolve();-->
<!--                };-->

<!--                websocket.onmessage = async (event) => {-->
<!--                    if (event.data instanceof Blob) {-->
<!--                        // Audio data received-->
<!--                        console.log('Received audio blob:', event.data.size, 'bytes');-->
<!--                        const arrayBuffer = await event.data.arrayBuffer();-->
<!--                        audioQueue.push(arrayBuffer);-->
<!--                        processAudioQueue();-->
<!--                    } else {-->
<!--                        // JSON message-->
<!--                        const data = JSON.parse(event.data);-->
<!--                        console.log('Received:', data);-->

<!--                        if (data.type === 'status') {-->
<!--                            updateStatus(data.message, data.message.includes('Speaking') ? 'processing' : 'listening');-->
<!--                        } else if (data.type === 'transcript') {-->
<!--                            addToConversation(data.text, true);-->
<!--                        } else if (data.type === 'response') {-->
<!--                            addToConversation(data.text, false);-->
<!--                        } else if (data.type === 'interim_transcript') {-->
<!--                            updateStatus(`Hearing: "${data.text}"`, 'listening');-->
<!--                        } else if (data.type === 'audio_complete') {-->
<!--                            console.log('Audio playback complete');-->
<!--                        } else if (data.type === 'error') {-->
<!--                            showError(data.message);-->
<!--                        }-->
<!--                    }-->
<!--                };-->

<!--                websocket.onerror = (error) => {-->
<!--                    console.error('WebSocket error:', error);-->
<!--                    showError('Connection error occurred');-->
<!--                    reject(error);-->
<!--                };-->

<!--                websocket.onclose = () => {-->
<!--                    console.log('WebSocket closed');-->
<!--                    updateStatus('Disconnected - Click mic to reconnect', '');-->
<!--                    isListening = false;-->
<!--                    websocket = null;-->
<!--                };-->

<!--                // Timeout after 5 seconds-->
<!--                setTimeout(() => {-->
<!--                    if (websocket && websocket.readyState !== WebSocket.OPEN) {-->
<!--                        reject(new Error('Connection timeout'));-->
<!--                    }-->
<!--                }, 5000);-->
<!--            });-->
<!--        }-->

<!--        async function startListening() {-->
<!--            try {-->
<!--                const stream = await navigator.mediaDevices.getUserMedia({-->
<!--                    audio: {-->
<!--                        channelCount: 1,-->
<!--                        sampleRate: 16000,-->
<!--                        echoCancellation: true,-->
<!--                        noiseSuppression: true,-->
<!--                        autoGainControl: true-->
<!--                    }-->
<!--                });-->

<!--                console.log('Microphone access granted');-->

<!--                audioContext = new (window.AudioContext || window.webkitAudioContext)({-->
<!--                    sampleRate: 16000-->
<!--                });-->

<!--                await audioContext.resume();-->

<!--                const source = audioContext.createMediaStreamSource(stream);-->
<!--                const processor = audioContext.createScriptProcessor(4096, 1, 1);-->

<!--                source.connect(processor);-->
<!--                processor.connect(audioContext.destination);-->

<!--                processor.onaudioprocess = (e) => {-->
<!--                    if (websocket && websocket.readyState === WebSocket.OPEN && isListening) {-->
<!--                        const inputData = e.inputBuffer.getChannelData(0);-->

<!--                        // Convert to 16-bit PCM-->
<!--                        const pcm16 = new Int16Array(inputData.length);-->
<!--                        for (let i = 0; i < inputData.length; i++) {-->
<!--                            const s = Math.max(-1, Math.min(1, inputData[i]));-->
<!--                            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;-->
<!--                        }-->

<!--                        // Send as bytes-->
<!--                        websocket.send(pcm16.buffer);-->
<!--                    }-->
<!--                };-->

<!--                mediaRecorder = { stream, processor, source };-->
<!--                isListening = true;-->
<!--                updateStatus('Listening... Speak now', 'listening');-->
<!--                console.log('Started listening');-->

<!--            } catch (error) {-->
<!--                console.error('Error starting microphone:', error);-->
<!--                showError('Could not access microphone: ' + error.message);-->
<!--            }-->
<!--        }-->

<!--        function stopListening() {-->
<!--            if (mediaRecorder) {-->
<!--                console.log('Stopping microphone');-->
<!--                mediaRecorder.stream.getTracks().forEach(track => track.stop());-->
<!--                mediaRecorder.processor.disconnect();-->
<!--                mediaRecorder.source.disconnect();-->
<!--                if (audioContext) {-->
<!--                    audioContext.close();-->
<!--                    audioContext = null;-->
<!--                }-->
<!--                mediaRecorder = null;-->
<!--            }-->
<!--            isListening = false;-->
<!--            updateStatus('Stopped - Click to start again', '');-->
<!--        }-->

<!--        micButton.addEventListener('click', async () => {-->
<!--            try {-->
<!--                if (!websocket || websocket.readyState !== WebSocket.OPEN) {-->
<!--                    updateStatus('Connecting...', 'processing');-->
<!--                    await connectWebSocket();-->
<!--                    // Wait a moment for welcome message-->
<!--                    await new Promise(resolve => setTimeout(resolve, 1500));-->
<!--                    await startListening();-->
<!--                } else if (isListening) {-->
<!--                    stopListening();-->
<!--                } else {-->
<!--                    await startListening();-->
<!--                }-->
<!--            } catch (error) {-->
<!--                console.error('Error:', error);-->
<!--                showError('Failed to connect or start microphone: ' + error.message);-->
<!--                updateStatus('Error - Click to retry', '');-->
<!--            }-->
<!--        });-->

<!--        clearBtn.addEventListener('click', () => {-->
<!--            conversation.innerHTML = '<span class="transcript-label">Conversation:</span>';-->
<!--            if (websocket && websocket.readyState === WebSocket.OPEN) {-->
<!--                websocket.close();-->
<!--            }-->
<!--            websocket = null;-->
<!--            stopListening();-->
<!--            audioQueue = [];-->
<!--            isPlayingAudio = false;-->
<!--            updateStatus('Click microphone to start', '');-->
<!--        });-->

<!--        // Cleanup on page unload-->
<!--        window.addEventListener('beforeunload', () => {-->
<!--            if (websocket) {-->
<!--                websocket.close();-->
<!--            }-->
<!--            stopListening();-->
<!--        });-->
<!--    </script>-->
<!--</body>-->
<!--</html>-->

<!--new version generated by claude-->

<!--<!DOCTYPE html>-->
<!--<html lang="en">-->
<!--<head>-->
<!--    <meta charset="UTF-8">-->
<!--    <meta name="viewport" content="width=device-width, initial-scale=1.0">-->
<!--    <title>Voice Medical Appointment Assistant - Powered by Deepgram SDK</title>-->
<!--    <style>-->
<!--        * {-->
<!--            margin: 0;-->
<!--            padding: 0;-->
<!--            box-sizing: border-box;-->
<!--        }-->

<!--        body {-->
<!--            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            height: 100vh;-->
<!--            display: flex;-->
<!--            justify-content: center;-->
<!--            align-items: center;-->
<!--            padding: 20px;-->
<!--        }-->

<!--        .voice-container {-->
<!--            width: 100%;-->
<!--            max-width: 800px;-->
<!--            background: white;-->
<!--            border-radius: 20px;-->
<!--            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);-->
<!--            padding: 40px;-->
<!--            text-align: center;-->
<!--        }-->

<!--        .header {-->
<!--            margin-bottom: 30px;-->
<!--        }-->

<!--        .header h1 {-->
<!--            font-size: 32px;-->
<!--            color: #667eea;-->
<!--            margin-bottom: 10px;-->
<!--        }-->

<!--        .header p {-->
<!--            color: #666;-->
<!--            font-size: 16px;-->
<!--        }-->

<!--        .mode-toggle {-->
<!--            display: flex;-->
<!--            justify-content: center;-->
<!--            gap: 10px;-->
<!--            margin-bottom: 30px;-->
<!--        }-->

<!--        .mode-btn {-->
<!--            padding: 10px 20px;-->
<!--            border: 2px solid #667eea;-->
<!--            background: white;-->
<!--            color: #667eea;-->
<!--            border-radius: 25px;-->
<!--            cursor: pointer;-->
<!--            font-size: 14px;-->
<!--            font-weight: 600;-->
<!--            transition: all 0.3s;-->
<!--        }-->

<!--        .mode-btn.active {-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            color: white;-->
<!--        }-->

<!--        .mode-btn:hover {-->
<!--            transform: translateY(-2px);-->
<!--            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);-->
<!--        }-->

<!--        .microphone-wrapper {-->
<!--            margin: 40px 0;-->
<!--        }-->

<!--        .microphone-button {-->
<!--            width: 120px;-->
<!--            height: 120px;-->
<!--            border-radius: 50%;-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            border: none;-->
<!--            cursor: pointer;-->
<!--            display: inline-flex;-->
<!--            align-items: center;-->
<!--            justify-content: center;-->
<!--            transition: all 0.3s;-->
<!--            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);-->
<!--        }-->

<!--        .microphone-button:hover {-->
<!--            transform: scale(1.1);-->
<!--            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.6);-->
<!--        }-->

<!--        .microphone-button.listening {-->
<!--            animation: pulse 1.5s infinite;-->
<!--            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);-->
<!--        }-->

<!--        .microphone-button.processing {-->
<!--            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);-->
<!--        }-->

<!--        @keyframes pulse {-->
<!--            0%, 100% {-->
<!--                transform: scale(1);-->
<!--                box-shadow: 0 10px 30px rgba(240, 147, 251, 0.4);-->
<!--            }-->
<!--            50% {-->
<!--                transform: scale(1.1);-->
<!--                box-shadow: 0 15px 40px rgba(240, 147, 251, 0.6);-->
<!--            }-->
<!--        }-->

<!--        .microphone-icon {-->
<!--            font-size: 48px;-->
<!--            color: white;-->
<!--        }-->

<!--        .status {-->
<!--            font-size: 18px;-->
<!--            color: #667eea;-->
<!--            margin: 20px 0;-->
<!--            min-height: 30px;-->
<!--            font-weight: 600;-->
<!--        }-->

<!--        .transcript-section {-->
<!--            margin: 30px 0;-->
<!--            text-align: left;-->
<!--        }-->

<!--        .transcript-box {-->
<!--            background: #f7f7f7;-->
<!--            border-radius: 15px;-->
<!--            padding: 20px;-->
<!--            min-height: 150px;-->
<!--            max-height: 300px;-->
<!--            overflow-y: auto;-->
<!--        }-->

<!--        .transcript-label {-->
<!--            font-weight: 600;-->
<!--            color: #667eea;-->
<!--            margin-bottom: 10px;-->
<!--            display: block;-->
<!--        }-->

<!--        .transcript-text {-->
<!--            color: #333;-->
<!--            line-height: 1.6;-->
<!--            margin-bottom: 15px;-->
<!--        }-->

<!--        .transcript-text.user {-->
<!--            color: #764ba2;-->
<!--            font-weight: 500;-->
<!--        }-->

<!--        .transcript-text.assistant {-->
<!--            color: #667eea;-->
<!--        }-->

<!--        .controls {-->
<!--            display: flex;-->
<!--            justify-content: center;-->
<!--            gap: 15px;-->
<!--            margin-top: 30px;-->
<!--        }-->

<!--        .control-btn {-->
<!--            padding: 12px 24px;-->
<!--            border: none;-->
<!--            border-radius: 25px;-->
<!--            cursor: pointer;-->
<!--            font-size: 14px;-->
<!--            font-weight: 600;-->
<!--            transition: all 0.3s;-->
<!--        }-->

<!--        .control-btn.primary {-->
<!--            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);-->
<!--            color: white;-->
<!--        }-->

<!--        .control-btn.secondary {-->
<!--            background: #f44336;-->
<!--            color: white;-->
<!--        }-->

<!--        .control-btn:hover {-->
<!--            transform: translateY(-2px);-->
<!--            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);-->
<!--        }-->

<!--        .control-btn:disabled {-->
<!--            opacity: 0.5;-->
<!--            cursor: not-allowed;-->
<!--            transform: none;-->
<!--        }-->

<!--        .error-message {-->
<!--            background: #ffebee;-->
<!--            color: #c62828;-->
<!--            padding: 15px;-->
<!--            border-radius: 10px;-->
<!--            margin-top: 20px;-->
<!--            display: none;-->
<!--        }-->

<!--        .error-message.show {-->
<!--            display: block;-->
<!--        }-->

<!--        .back-link {-->
<!--            margin-top: 20px;-->
<!--        }-->

<!--        .back-link a {-->
<!--            color: #667eea;-->
<!--            text-decoration: none;-->
<!--            font-weight: 600;-->
<!--        }-->

<!--        .back-link a:hover {-->
<!--            text-decoration: underline;-->
<!--        }-->
<!--    </style>-->
<!--</head>-->
<!--<body>-->
<!--    <div class="voice-container">-->
<!--        <div class="header">-->
<!--            <h1>üé§ Voice Medical Assistant</h1>-->
<!--            <p>Talk to book, cancel, or manage your appointments</p>-->
<!--        </div>-->

<!--        <div class="mode-toggle">-->
<!--            <a href="/" style="text-decoration: none;">-->
<!--                <button class="mode-btn">üí¨ Text Chat</button>-->
<!--            </a>-->
<!--            <button class="mode-btn active">üé§ Voice Chat</button>-->
<!--        </div>-->

<!--        <div class="microphone-wrapper">-->
<!--            <button class="microphone-button" id="micButton">-->
<!--                <span class="microphone-icon">üé§</span>-->
<!--            </button>-->
<!--        </div>-->

<!--        <div class="status" id="status">Click microphone to start</div>-->

<!--        <div class="transcript-section">-->
<!--            <div class="transcript-box" id="transcriptBox">-->
<!--                <span class="transcript-label">Conversation:</span>-->
<!--                <div id="conversation"></div>-->
<!--            </div>-->
<!--        </div>-->

<!--        <div class="controls">-->
<!--            <button class="control-btn secondary" id="clearBtn">Clear Conversation</button>-->
<!--        </div>-->

<!--        <div class="error-message" id="errorMessage"></div>-->

<!--        <div class="back-link">-->
<!--            <a href="/">‚Üê Switch to Text Chat</a>-->
<!--        </div>-->
<!--    </div>-->

<!--    <script>-->
<!--        let websocket = null;-->
<!--        let mediaRecorder = null;-->
<!--        let audioContext = null;-->
<!--        let isListening = false;-->
<!--        let audioQueue = [];-->
<!--        let isPlayingAudio = false;-->

<!--        const micButton = document.getElementById('micButton');-->
<!--        const status = document.getElementById('status');-->
<!--        const conversation = document.getElementById('conversation');-->
<!--        const errorMessage = document.getElementById('errorMessage');-->
<!--        const clearBtn = document.getElementById('clearBtn');-->

<!--        function showError(message) {-->
<!--            errorMessage.textContent = message;-->
<!--            errorMessage.classList.add('show');-->
<!--            setTimeout(() => {-->
<!--                errorMessage.classList.remove('show');-->
<!--            }, 5000);-->
<!--        }-->

<!--        function updateStatus(message, className = '') {-->
<!--            status.textContent = message;-->
<!--            micButton.className = 'microphone-button ' + className;-->
<!--        }-->

<!--        function addToConversation(text, isUser) {-->
<!--            const div = document.createElement('div');-->
<!--            div.className = `transcript-text ${isUser ? 'user' : 'assistant'}`;-->
<!--            div.textContent = `${isUser ? 'You' : 'Assistant'}: ${text}`;-->
<!--            conversation.appendChild(div);-->
<!--            document.getElementById('transcriptBox').scrollTop = document.getElementById('transcriptBox').scrollHeight;-->
<!--        }-->

<!--        async function playAudio(audioData) {-->
<!--            return new Promise((resolve) => {-->
<!--                if (!audioContext) {-->
<!--                    audioContext = new (window.AudioContext || window.webkitAudioContext)();-->
<!--                }-->

<!--                audioContext.decodeAudioData(audioData, (buffer) => {-->
<!--                    const source = audioContext.createBufferSource();-->
<!--                    source.buffer = buffer;-->
<!--                    source.connect(audioContext.destination);-->

<!--                    source.onended = () => {-->
<!--                        resolve();-->
<!--                    };-->

<!--                    source.start(0);-->
<!--                }, (error) => {-->
<!--                    console.error('Audio decode error:', error);-->
<!--                    resolve();-->
<!--                });-->
<!--            });-->
<!--        }-->

<!--        async function processAudioQueue() {-->
<!--            if (isPlayingAudio || audioQueue.length === 0) return;-->

<!--            isPlayingAudio = true;-->
<!--            const audioData = audioQueue.shift();-->
<!--            await playAudio(audioData);-->
<!--            isPlayingAudio = false;-->

<!--            if (audioQueue.length > 0) {-->
<!--                processAudioQueue();-->
<!--            }-->
<!--        }-->

<!--        async function connectWebSocket() {-->
<!--            return new Promise((resolve, reject) => {-->
<!--                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';-->
<!--&lt;!&ndash;                const wsUrl = `${protocol}//${window.location.host}/api/voice/ws`;&ndash;&gt;-->
<!--                const pathParts = location.pathname.split("/").filter(Boolean);-->
<!--                const basePath = pathParts.length > 0 ? `/${pathParts[0]}` : "";-->

<!--                const wsUrl = `${protocol}//${location.host}${basePath}/api/voice/ws`;-->

<!--                console.log('Connecting to:', wsUrl);-->
<!--                websocket = new WebSocket(wsUrl);-->

<!--                websocket.onopen = () => {-->
<!--                    console.log('WebSocket connected');-->
<!--                    updateStatus('Connected - Ready to listen', '');-->
<!--                    resolve();-->
<!--                };-->

<!--                websocket.onmessage = async (event) => {-->
<!--                    if (event.data instanceof Blob) {-->
<!--                        // Audio data received-->
<!--                        console.log('Received audio blob:', event.data.size, 'bytes');-->
<!--                        const arrayBuffer = await event.data.arrayBuffer();-->
<!--                        audioQueue.push(arrayBuffer);-->
<!--                        processAudioQueue();-->
<!--                    } else {-->
<!--                        // JSON message-->
<!--                        const data = JSON.parse(event.data);-->
<!--                        console.log('Received:', data);-->

<!--                        if (data.type === 'status') {-->
<!--                            updateStatus(data.message, data.message.includes('Speaking') ? 'processing' : 'listening');-->
<!--                        } else if (data.type === 'transcript') {-->
<!--                            addToConversation(data.text, true);-->
<!--                        } else if (data.type === 'response') {-->
<!--                            addToConversation(data.text, false);-->
<!--                        } else if (data.type === 'interim_transcript') {-->
<!--                            updateStatus(`Hearing: "${data.text}"`, 'listening');-->
<!--                        } else if (data.type === 'audio_complete') {-->
<!--                            console.log('Audio playback complete');-->
<!--                        } else if (data.type === 'error') {-->
<!--                            showError(data.message);-->
<!--                        }-->
<!--                    }-->
<!--                };-->

<!--                websocket.onerror = (error) => {-->
<!--                    console.error('WebSocket error:', error);-->
<!--                    showError('Connection error occurred');-->
<!--                    reject(error);-->
<!--                };-->

<!--                websocket.onclose = () => {-->
<!--                    console.log('WebSocket closed');-->
<!--                    updateStatus('Disconnected - Click mic to reconnect', '');-->
<!--                    isListening = false;-->
<!--                    websocket = null;-->
<!--                };-->

<!--                // Timeout after 5 seconds-->
<!--                setTimeout(() => {-->
<!--                    if (websocket && websocket.readyState !== WebSocket.OPEN) {-->
<!--                        reject(new Error('Connection timeout'));-->
<!--                    }-->
<!--                }, 5000);-->
<!--            });-->
<!--        }-->

<!--        async function startListening() {-->
<!--            try {-->
<!--                const stream = await navigator.mediaDevices.getUserMedia({-->
<!--                    audio: true-->
<!--                });-->

<!--                console.log('Microphone access granted');-->

<!--                // Use MediaRecorder for better audio capture-->
<!--                mediaRecorder = new MediaRecorder(stream, {-->
<!--                    mimeType: 'audio/webm'-->
<!--                });-->

<!--                mediaRecorder.ondataavailable = (event) => {-->
<!--                    if (event.data.size > 0 && websocket && websocket.readyState === WebSocket.OPEN) {-->
<!--                        websocket.send(event.data);-->
<!--                    }-->
<!--                };-->

<!--                mediaRecorder.onstart = () => {-->
<!--                    console.log('Recording started');-->
<!--                    isListening = true;-->
<!--                    updateStatus('Listening... Speak now', 'listening');-->
<!--                };-->

<!--                mediaRecorder.onstop = () => {-->
<!--                    console.log('Recording stopped');-->
<!--                };-->

<!--                // Start recording with 100ms chunks-->
<!--                mediaRecorder.start(100);-->

<!--                console.log('Started listening');-->

<!--            } catch (error) {-->
<!--                console.error('Error starting microphone:', error);-->
<!--                showError('Could not access microphone: ' + error.message);-->
<!--            }-->
<!--        }-->

<!--        function stopListening() {-->
<!--            if (mediaRecorder && mediaRecorder.state === 'recording') {-->
<!--                console.log('Stopping microphone');-->
<!--                mediaRecorder.stop();-->
<!--                mediaRecorder.stream.getTracks().forEach(track => track.stop());-->
<!--                mediaRecorder = null;-->
<!--                isListening = false;-->
<!--                updateStatus('Stopped - Click to start again', '');-->
<!--            }-->
<!--        }-->

<!--        micButton.addEventListener('click', async () => {-->
<!--            try {-->
<!--                if (!websocket || websocket.readyState !== WebSocket.OPEN) {-->
<!--                    updateStatus('Connecting...', 'processing');-->
<!--                    await connectWebSocket();-->
<!--                    // Wait a moment for welcome message-->
<!--                    await new Promise(resolve => setTimeout(resolve, 1500));-->
<!--                    await startListening();-->
<!--                } else if (isListening) {-->
<!--                    stopListening();-->
<!--                } else {-->
<!--                    await startListening();-->
<!--                }-->
<!--            } catch (error) {-->
<!--                console.error('Error:', error);-->
<!--                showError('Failed to connect or start microphone: ' + error.message);-->
<!--                updateStatus('Error - Click to retry', '');-->
<!--            }-->
<!--        });-->

<!--        clearBtn.addEventListener('click', () => {-->
<!--            conversation.innerHTML = '<span class="transcript-label">Conversation:</span>';-->
<!--            if (websocket && websocket.readyState === WebSocket.OPEN) {-->
<!--                websocket.close();-->
<!--            }-->
<!--            websocket = null;-->
<!--            stopListening();-->
<!--            audioQueue = [];-->
<!--            isPlayingAudio = false;-->
<!--            updateStatus('Click microphone to start', '');-->
<!--        });-->

<!--        // Cleanup on page unload-->
<!--        window.addEventListener('beforeunload', () => {-->
<!--            if (websocket) {-->
<!--                websocket.close();-->
<!--            }-->
<!--            stopListening();-->
<!--        });-->
<!--    </script>-->
<!--</body>-->
<!--</html>-->


<!--new version generated by chatgpt-->


<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<title>Medilligence ‚Ä¢ Voice Assistant</title>

<style>
* { margin: 0; padding: 0; box-sizing: border-box; }

body {
    font-family: "Segoe UI", system-ui, sans-serif;
    background: #f4f7fb;
    height: 100vh;
    display: flex;
    justify-content: center;
    align-items: center;
}

.voice-container {
    width: 100%;
    max-width: 820px;
    height: 92vh;
    background: #ffffff;
    border-radius: 18px;
    box-shadow: 0 18px 40px rgba(0,0,0,0.12);
    display: flex;
    flex-direction: column;
    overflow: hidden;
}

.voice-header {
    background: #2563eb;
    color: white;
    padding: 16px 20px;
    display: flex;
    align-items: center;
    gap: 12px;
}

.voice-header .back {
    cursor: pointer;
    font-size: 18px;
}

.voice-header h1 {
    font-size: 18px;
    font-weight: 600;
}

.voice-header p {
    font-size: 12px;
    opacity: 0.9;
}

.voice-messages {
    flex: 1;
    padding: 20px;
    background: #f9fafb;
    overflow-y: auto;
}

.message {
    display: flex;
    margin-bottom: 14px;
}

.message.user { justify-content: flex-end; }
.message.assistant { justify-content: flex-start; }

.bubble {
    max-width: 70%;
    padding: 12px 16px;
    border-radius: 16px;
    font-size: 14px;
    line-height: 1.5;
}

.message.user .bubble {
    background: #2563eb;
    color: white;
    border-bottom-right-radius: 4px;
}

.message.assistant .bubble {
    background: #eef2f7;
    color: #1f2937;
    border-bottom-left-radius: 4px;
}

.voice-bar {
    border-top: 1px solid #e5e7eb;
    padding: 14px 18px;
    display: flex;
    align-items: center;
    gap: 14px;
    background: #ffffff;
}

.chat-icon {
    width: 42px;
    height: 42px;
    border-radius: 50%;
    border: none;
    background: #e0e7ff;
    color: #2563eb;
    font-size: 18px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mic-area {
    flex: 1;
    background: #f3f4f6;
    border-radius: 28px;
    padding: 10px 16px;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 10px;
    cursor: pointer;
}

.mic {
    width: 44px;
    height: 44px;
    border-radius: 50%;
    background: #2563eb;
    color: white;
    font-size: 20px;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mic.listening {
    animation: pulse 1.4s infinite;
}

@keyframes pulse {
    0% { box-shadow: 0 0 0 0 rgba(37,99,235,0.6); }
    70% { box-shadow: 0 0 0 14px rgba(37,99,235,0); }
    100% { box-shadow: 0 0 0 0 rgba(37,99,235,0); }
}

.status {
    font-size: 13px;
    color: #374151;
}

.clear-btn {
    font-size: 12px;
    background: none;
    border: none;
    color: #6b7280;
    cursor: pointer;
    padding: 10px;
}
</style>
</head>

<body>

<div class="voice-container">
    <div class="voice-header">
        <div class="back" onclick="goToText()">üí¨</div>
        <div>
            <h1>Medilligence</h1>
            <p>Voice Assistant ‚Ä¢ Manage appointments</p>
        </div>
    </div>

    <div class="voice-messages" id="chat">
        <div class="message assistant">
            <div class="bubble">
                Hello! I'm your medical appointment assistant. How can I help you today?
            </div>
        </div>
    </div>

    <div class="voice-bar">
        <button class="chat-icon" onclick="goToText()">üí¨</button>

        <div class="mic-area" id="micButton">
            <div class="mic" id="micIcon">üé§</div>
            <div class="status" id="status">Tap to speak</div>
        </div>

        <button class="clear-btn" id="clearBtn">Clear</button>
    </div>
</div>

<script>
function goToText() {
    window.location.href = "./";
}

const chat = document.getElementById("chat");
const statusEl = document.getElementById("status");
const micIcon = document.getElementById("micIcon");
const micButton = document.getElementById("micButton");
const clearBtn = document.getElementById("clearBtn");

let websocket = null;
let isListening = false;
let mediaRecorder = null;
let audioContext = null;
let audioQueue = [];
let isPlayingAudio = false;

/* ---------------- UI HELPERS ---------------- */

function addMessage(text, isUser) {
    const msg = document.createElement("div");
    msg.className = "message " + (isUser ? "user" : "assistant");

    const bubble = document.createElement("div");
    bubble.className = "bubble";
    bubble.textContent = text;

    msg.appendChild(bubble);
    chat.appendChild(msg);
    chat.scrollTop = chat.scrollHeight;
}

function updateStatus(text, listening = false) {
    statusEl.textContent = text;
    micIcon.classList.toggle("listening", listening);

    // üîí mic enabled ONLY when backend says Listening...
    if (text === "Listening...") {
        micButton.classList.remove("disabled");
    } else {
        micButton.classList.add("disabled");
    }
}

/* ---------------- AUDIO INIT ---------------- */

<!--async function initAudio() {-->
<!--    try {-->
<!--        audioContext = new (window.AudioContext || window.webkitAudioContext)();-->
<!--        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });-->

<!--&lt;!&ndash;        mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm" });&ndash;&gt;-->

<!--&lt;!&ndash;        mediaRecorder.ondataavailable = (event) => {&ndash;&gt;-->
<!--&lt;!&ndash;            if (event.data.size > 0 && websocket?.readyState === WebSocket.OPEN) {&ndash;&gt;-->
<!--&lt;!&ndash;                websocket.send(event.data);&ndash;&gt;-->
<!--&lt;!&ndash;            }&ndash;&gt;-->
<!--&lt;!&ndash;        };&ndash;&gt;-->

<!--        return true;-->
<!--    } catch (error) {-->
<!--        console.error("Mic error:", error);-->
<!--        updateStatus("Microphone access denied");-->
<!--        return false;-->
<!--    }-->
<!--}-->

async function initAudio() {
    try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: 16000   // IMPORTANT
        });

        await audioContext.resume();

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const source = audioContext.createMediaStreamSource(stream);

        await audioContext.audioWorklet.addModule("static/pcm-processor.js");

        const worklet = new AudioWorkletNode(audioContext, "pcm-processor");

        worklet.port.onmessage = (event) => {
            if (websocket?.readyState === WebSocket.OPEN) {
                websocket.send(event.data); // raw PCM bytes
            }
        };

        source.connect(worklet);
        worklet.connect(audioContext.destination); // optional (monitor)

        return true;
    } catch (err) {
        console.error("Audio init failed:", err);
        updateStatus("Microphone error");
        return false;
    }
}

/* ---------------- MIC CONTROL ---------------- */

micButton.addEventListener("click", async () => {
    if (micButton.classList.contains("disabled")) return;

    if (!websocket) {
        updateStatus("Connecting...");
        await connectWebSocket();
        return;
    }

    isListening ? stopListening() : startListening();
});

<!--function startListening() {-->
<!--    if (!mediaRecorder) return;-->
<!--    if (statusEl.textContent !== "Listening...") return;-->

<!--    if (mediaRecorder.state === "inactive") {-->
<!--        mediaRecorder.start(100);-->
<!--        isListening = true;-->
<!--        updateStatus("Listening‚Ä¶", true);-->
<!--    }-->
<!--}-->

<!--function stopListening() {-->
<!--    if (mediaRecorder?.state === "recording") {-->
<!--        mediaRecorder.stop();-->
<!--        isListening = false;-->
<!--        updateStatus("Processing...");-->
<!--    }-->
<!--}-->

function startListening() {
    isListening = true;
    updateStatus("Listening‚Ä¶", true);
}

function stopListening() {
    isListening = false;
    updateStatus("Processing...");
}


/* ---------------- WEBSOCKET ---------------- */

async function connectWebSocket() {
    if (!(await initAudio())) return;

    const protocol = location.protocol === "https:" ? "wss:" : "ws:";
    const pathParts = location.pathname.split("/").filter(Boolean);
    const basePath = pathParts.length ? `/${pathParts[0]}` : "";

    websocket = new WebSocket(`${protocol}//${location.host}${basePath}/api/voice/ws`);

<!--    const wsUrl = `${protocol}//${location.host}/api/voice/ws`;-->

<!--    websocket = new WebSocket(`${protocol}//${location.host}/api/voice/ws`);-->

    websocket.onopen = () => updateStatus("Connected");

    websocket.onmessage = async (e) => {
        if (e.data instanceof Blob) {
            audioQueue.push(e.data);
            if (!isPlayingAudio) playNextAudio();
            return;
        }

        const data = JSON.parse(e.data);

        if (data.type === "status") {
            updateStatus(data.message, data.message === "Listening...");
        }
        else if (data.type === "interim_transcript") {
            updateStatus("Hearing: " + data.text.substring(0, 30) + "‚Ä¶", true);
        }
        else if (data.type === "transcript") {
            addMessage(data.text, true);
        }
        else if (data.type === "response") {
            addMessage(data.text, false);
        }
        else if (data.type === "error") {
            updateStatus("Error: " + data.message);
        }
    };

    websocket.onerror = () => updateStatus("Connection error");
    websocket.onclose = () => {
        websocket = null;
        updateStatus("Tap to speak");
    };
}

/* ---------------- AUDIO PLAYBACK ---------------- */

async function playNextAudio() {
    if (!audioQueue.length) {
        isPlayingAudio = false;
        return; // üîí backend controls status
    }

    isPlayingAudio = true;

    try {
        const audioBlob = audioQueue.shift();
        const buffer = await audioContext.decodeAudioData(await audioBlob.arrayBuffer());

        const source = audioContext.createBufferSource();
        source.buffer = buffer;
        source.connect(audioContext.destination);
        source.onended = playNextAudio;
        source.start(0);
    } catch {
        playNextAudio();
    }
}

/* ---------------- CLEAR ---------------- */

clearBtn.onclick = () => {
    chat.innerHTML = `
        <div class="message assistant">
            <div class="bubble">
                Hello! I'm your medical appointment assistant. How can I help you today?
            </div>
        </div>`;
    updateStatus("Tap to speak");
};

/* ---------------- CLEANUP ---------------- */

window.addEventListener("beforeunload", () => {
    websocket?.close();
    if (mediaRecorder?.state === "recording") mediaRecorder.stop();
});
</script>

</body>
</html>

